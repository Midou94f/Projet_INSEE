{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b378c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x).rstrip('0').rstrip('.') if x != 0 else '0')\n",
    "import numpy as np \n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "import polars as pl \n",
    "pl.Config(set_fmt_float=\"full\")\n",
    "pl.Config(tbl_cols=1000)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os \n",
    "import seaborn as sns\n",
    "np.random.seed(22)\n",
    "import torch \n",
    "from packages.utils2 import Optimize, JointOptimize\n",
    "from packages.utils2 import SaveParameters, LoadParameters, JointDisplayResults, JointSaveParameters, JointLoadParameters\n",
    "from packages.utils2 import prepare_data_level0, prepare_data_level1, prepare_data_level2, prepare_data_level3\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a790c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate your year of study :\n",
    "year=2009\n",
    "\n",
    "# load your data : \n",
    "data = pl.read_parquet(f'/your/path_to/data.parquet')\n",
    "\n",
    "# drop intrazonal observations:\n",
    "data = data.filter(pl.col('INTRAZONAL')==0)\n",
    "\n",
    "# normalized weights:\n",
    "data = data.with_columns(\n",
    "    WEIGHT_hh=((pl.col('IPONDI_m')+pl.col('IPONDI_w'))/2) * (len(data)/((pl.col('IPONDI_m')+pl.col('IPONDI_w'))/2).sum()),\n",
    "    WEIGHT_m=(pl.col('IPONDI_m')) * (len(data)/pl.col('IPONDI_m').sum()),\n",
    "    WEIGHT_w=(pl.col('IPONDI_w')) * (len(data)/pl.col('IPONDI_w').sum())\n",
    ")\n",
    "\n",
    "# transform to pandas for the optimization step:\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bebcb8",
   "metadata": {},
   "source": [
    "# Overall guidelines:\n",
    "\n",
    "- All parameters have to finish their names by _l* with * being the number of the level \\\n",
    "*For example : B_RES_INNERRING_l3 is the parameter of the \"couronne\" of the residential location in level 3*\n",
    "\n",
    "## Steps of estimation :\n",
    "\n",
    "1) Run the constraint model (without explanatory variables) \n",
    "2) Save the parameters of the constraint model, add some heterogeneity to the model \n",
    "3) Estimate again but with the parameters of the constraint model as initial values \n",
    "4) Save the parameters of the UNconstraint model (the one with heterogeneity)\n",
    "5) Add some new variables, estimate with the UNconstraint parameters as initial values\n",
    "6) Do it again until you are satified by your model \n",
    "\n",
    "## Tips :\n",
    "\n",
    "- To access a variable you have to use *var('my_variable')*, with **'my_variable'** being the name of the variable in your dataset \n",
    "- To add a variable with his associated parameter, you can name the parameter as you want (**by always adding the level at the end**) \\\n",
    "*For example : B_DIST_BIKE2_w_l0*var('DISTANCE')**2 \n",
    "- Note that we truncate the DISTANCE, TRAVEL TIME for WALK, BIKE and TC for a purpose of generalization when \\\n",
    "forcasting on different datasets where people could give extreme non-coherent values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc408e",
   "metadata": {},
   "source": [
    "# Level 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c201cbc",
   "metadata": {},
   "source": [
    "### Level 0 guidelines:\n",
    "\n",
    "- **!! IMPORTANT !!** :All parameters have to finish their names with _(gender)_l1 : **\"m\" for man and \"w\" for woman** \\\n",
    "*For example : B_WP_OUTERRING_m_l0 is the parameter of the \"couronne\" of the job location in level 1 for the man, B_WP_OUTERRING_w_l0 for woman*\n",
    "- Except for *sigma_l0* which is the same for the man and the woman\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- To add characteristics in the constant of a mode, you can add them in *XB* \\\n",
    "*For example : adding characteristics into XB_TC_m, is adding heterogeneity in the constant of the mode TC for the man*\n",
    "- To add characteristics in the VOT (value of time) of a mode, you can add them in the *torch.exp(delta_TT_MOTO_m_l0)* term \\\n",
    "For example :\n",
    "```python\n",
    "torch.exp(delta_TT_MOTO_m_l0 + VOT_OCCP_SELFEMPLOYED_MOTO_m_l0 * var('OCCP_SELFEMPLOYED_m')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18535866",
   "metadata": {},
   "source": [
    "### Level 0 function if your year of study is after 2016 (not included)\n",
    "\n",
    "- There is two different function for level 0 depending on the year of study : \\\n",
    "it is only after 2017 that INSEE has splitted MOTO and BIKE from the TWO WHEELS alternative. \\\n",
    "- So from 2017 there are 4 choices at the level 0 (BIKE, MOTO, TC and WALK), and before that \\\n",
    "there are 3 choices (TC, WALK and TWO WHEELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c47012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx_men = df['all_idx']\n",
    "        idx_women = df['all_idx']\n",
    "    else:\n",
    "        idx_men = df['men_idx']\n",
    "        idx_women = df['women_idx']\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_m_l0, ASC_BIKE_m_l0, ASC_TC_m_l0,\n",
    "\n",
    "    B_DIST_BIKE2_m_l0, \n",
    "    B_DIST_WALK2_m_l0,\n",
    "    B_TT_TC2_m_l0,\n",
    "    B_TT_MOTO2_m_l0,\n",
    "    delta_TT_TC_m_l0,\n",
    "    delta_TT_MOTO_m_l0,\n",
    "    delta_DIST_BIKE_m_l0,  \n",
    "\n",
    "    ASC_MOTO_w_l0, ASC_BIKE_w_l0, ASC_TC_w_l0,\n",
    "    \n",
    "    B_DIST_BIKE2_w_l0, \n",
    "    B_DIST_WALK2_w_l0,\n",
    "    B_TT_TC2_w_l0,\n",
    "    B_TT_MOTO2_w_l0,\n",
    "    delta_TT_TC_w_l0,\n",
    "    delta_TT_MOTO_w_l0,\n",
    "    delta_DIST_BIKE_w_l0\n",
    "    ) = params\n",
    "\n",
    "\n",
    "    # men :\n",
    "    XB_TC_m = (torch.tensor(0))\n",
    "\n",
    "    XB_MOTO_m = (torch.tensor(0))\n",
    "\n",
    "    XB_BIKE_m = (torch.tensor(0))\n",
    "\n",
    "    V_TC_m = (ASC_TC_m_l0 + XB_TC_m\n",
    "            - torch.exp(delta_TT_TC_m_l0) * torch.min(var('TT_TC_m'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_m_l0 * (torch.min(var('TT_TC_m'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK_m = (-3 * torch.min(var('DISTANCE_m'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_m_l0 * (torch.min(var('DISTANCE_m'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO_m = (ASC_MOTO_m_l0 + XB_MOTO_m\n",
    "              - torch.exp(delta_TT_MOTO_m_l0) * var('FREEFLOW_TT_m') \n",
    "              + B_TT_MOTO2_m_l0 * (var('FREEFLOW_TT_m')**2)) \n",
    "        \n",
    "    V_BIKE_m = (ASC_BIKE_m_l0 + XB_BIKE_m\n",
    "              - torch.exp(delta_DIST_BIKE_m_l0) * torch.min(var('DISTANCE_m'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_m_l0 * (torch.min(var('DISTANCE_m'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # women:\n",
    "    XB_TC_w = (torch.tensor(0))\n",
    "\n",
    "    XB_MOTO_w = (torch.tensor(0))\n",
    "\n",
    "    XB_BIKE_w = (torch.tensor(0))\n",
    "\n",
    "    # example of how heterogeneity can be added to the constant of BIKE for woman:\n",
    "    # XB_BIKE_w = (B_AGE40_BIKE_w_l0 * ((var('AGED_w')-40)/10) \n",
    "    #            + B_AGE40_BIKE2_w_l0 * (((var('AGED_w')-40)/10)**2))\n",
    "\n",
    "    # ------- Utility functions\n",
    "\n",
    "    V_TC_w = (ASC_TC_w_l0 + XB_TC_w\n",
    "            - torch.exp(delta_TT_TC_w_l0) * torch.min(var('TT_TC_w'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_w_l0 * (torch.min(var('TT_TC_w')**2, torch.tensor((180/60)))**2))\n",
    "\n",
    "    V_MOTO_w = (ASC_MOTO_w_l0 + XB_MOTO_w\n",
    "              - torch.exp(delta_TT_MOTO_w_l0) * var('FREEFLOW_TT_w') \n",
    "              + B_TT_MOTO2_w_l0 * (var('FREEFLOW_TT_w')**2)) \n",
    "    \n",
    "    V_WALK_w = (-3 * torch.min(var('DISTANCE_w'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_w_l0 * (torch.min(var('DISTANCE_w')**2, torch.tensor(10))**2) \n",
    "              ) \n",
    "    \n",
    "    V_BIKE_w = (ASC_BIKE_w_l0 + XB_BIKE_w\n",
    "              - torch.exp(delta_DIST_BIKE_w_l0) * torch.min(var('DISTANCE_w'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_w_l0 * (torch.min(var('DISTANCE_w')**2, torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # --------------- Men's probabilities\n",
    "    # https://stats.stackexchange.com/questions/304758/softmax-overflow\n",
    "    V_men_stack = torch.stack([V_TC_m[idx_men] / sigma_l0, \n",
    "                            V_MOTO_m[idx_men] / sigma_l0, \n",
    "                            V_WALK_m[idx_men] / sigma_l0, \n",
    "                            V_BIKE_m[idx_men] / sigma_l0], dim=1)\n",
    "    max_V_men = V_men_stack.max()\n",
    "    exp_V_men = torch.exp(V_men_stack - max_V_men)\n",
    "    sum_exp_men = exp_V_men.sum(dim=1)\n",
    "\n",
    "    P_TC_m, P_MOTO_m, P_WALK_m, P_BIKE_m = exp_V_men.T / sum_exp_men\n",
    "\n",
    "    # --------------- Women's probabilities\n",
    "    # https://stats.stackexchange.com/questions/304758/softmax-overflow\n",
    "    V_women_stack = torch.stack([V_TC_w[idx_women] / sigma_l0, \n",
    "                            V_MOTO_w[idx_women] / sigma_l0, \n",
    "                            V_WALK_w[idx_women] / sigma_l0, \n",
    "                            V_BIKE_w[idx_women] / sigma_l0], dim=1)\n",
    "    max_V_women = V_women_stack.max()\n",
    "    exp_V_women = torch.exp(V_women_stack - max_V_women)\n",
    "    sum_exp_women = exp_V_women.sum(dim=1)\n",
    "\n",
    "    P_TC_w, P_MOTO_w, P_WALK_w, P_BIKE_w = exp_V_women.T / sum_exp_women\n",
    "\n",
    "    # --------------- Choices\n",
    "\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC_m = torch.tensor((choices['COMMUTE_MODE_m']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK_m = torch.tensor((choices['COMMUTE_MODE_m']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO_m = torch.tensor((choices['COMMUTE_MODE_m']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE_m = torch.tensor((choices['COMMUTE_MODE_m']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    Choice_TC_w = torch.tensor((choices['COMMUTE_MODE_w']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK_w = torch.tensor((choices['COMMUTE_MODE_w']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO_w = torch.tensor((choices['COMMUTE_MODE_w']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE_w = torch.tensor((choices['COMMUTE_MODE_w']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights_m = var('WEIGHT_m')\n",
    "    weights_m = weights_m[idx_men]\n",
    "    weights_w = var('WEIGHT_w')\n",
    "    weights_w = weights_w[idx_women]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights_m * Choice_TC_m[idx_men] * torch.log(torch.sum(Choice_TC_m[idx_men])/len(idx_men))) + \\\n",
    "                torch.sum(weights_m * Choice_MOTO_m[idx_men] * torch.log(torch.sum(Choice_MOTO_m[idx_men])/len(idx_men))) + \\\n",
    "                torch.sum(weights_m * Choice_WALK_m[idx_men] * torch.log(torch.sum(Choice_WALK_m[idx_men])/len(idx_men))) + \\\n",
    "                torch.sum(weights_m * Choice_BIKE_m[idx_men] * torch.log(torch.sum(Choice_BIKE_m[idx_men])/len(idx_men))) + \\\n",
    "                torch.sum(weights_w * Choice_TC_w[idx_women] * torch.log(torch.sum(Choice_TC_w[idx_women])/len(idx_women))) + \\\n",
    "                torch.sum(weights_w * Choice_MOTO_w[idx_women] * torch.log(torch.sum(Choice_MOTO_w[idx_women])/len(idx_women))) + \\\n",
    "                torch.sum(weights_w * Choice_WALK_w[idx_women] * torch.log(torch.sum(Choice_WALK_w[idx_women])/len(idx_women))) + \\\n",
    "                torch.sum(weights_w * Choice_BIKE_w[idx_women] * torch.log(torch.sum(Choice_BIKE_w[idx_women])/len(idx_women)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "\n",
    "    LL = torch.sum(weights_m * Choice_TC_m[idx_men] * torch.log(torch.clamp(P_TC_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_m * Choice_MOTO_m[idx_men] * torch.log(torch.clamp(P_MOTO_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_m * Choice_WALK_m[idx_men] * torch.log(torch.clamp(P_WALK_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_m * Choice_BIKE_m[idx_men] * torch.log(torch.clamp(P_BIKE_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_TC_w[idx_women] * torch.log(torch.clamp(P_TC_w, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_MOTO_w[idx_women] * torch.log(torch.clamp(P_MOTO_w, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_WALK_w[idx_women] * torch.log(torch.clamp(P_WALK_w, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_BIKE_w[idx_women] * torch.log(torch.clamp(P_BIKE_w, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS_m = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC_m / sigma_l0) + torch.exp(V_MOTO_m / sigma_l0) \n",
    "            + torch.exp(V_WALK_m / sigma_l0) + torch.exp(V_BIKE_m / sigma_l0) \n",
    "        )\n",
    "        LS_w = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC_w / sigma_l0) + torch.exp(V_MOTO_w / sigma_l0) \n",
    "            + torch.exp(V_WALK_w / sigma_l0) + torch.exp(V_BIKE_w / sigma_l0) \n",
    "        )\n",
    "        return LS_m, LS_w\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx_men) + len(idx_women)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eccd8a8",
   "metadata": {},
   "source": [
    "### Level 0 function if your year of study is before 2016 (included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx_men = df['all_idx']\n",
    "        idx_women = df['all_idx']\n",
    "    else:\n",
    "        idx_men = df['men_idx']\n",
    "        idx_women = df['women_idx']\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (\n",
    "        sigma_l0, \n",
    "        ASC_2R_m_l0, ASC_TC_m_l0,\n",
    "\n",
    "        B_DIST_2R2_m_l0, \n",
    "        B_DIST_WALK2_m_l0,\n",
    "        B_TT_TC2_m_l0,\n",
    "        delta_TT_TC_m_l0,\n",
    "        delta_DIST_2R_m_l0,  \n",
    "\n",
    "        ASC_2R_w_l0, ASC_TC_w_l0,\n",
    "\n",
    "        B_DIST_2R2_w_l0, \n",
    "        B_DIST_WALK2_w_l0,\n",
    "        B_TT_TC2_w_l0,\n",
    "        delta_TT_TC_w_l0,\n",
    "        delta_DIST_2R_w_l0,\n",
    "\n",
    "    ) = params\n",
    "\n",
    "\n",
    "    # men :\n",
    "    XB_TC_m = (torch.tensor(0))\n",
    "\n",
    "    XB_2R_m = (torch.tensor(0))\n",
    "\n",
    "    V_TC_m = (ASC_TC_m_l0 + XB_TC_m\n",
    "            - torch.exp(delta_TT_TC_m_l0) * torch.min(var('TT_TC_m'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_m_l0 * (torch.min(var('TT_TC_m'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK_m = (-3 * torch.min(var('DISTANCE_m'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_m_l0 * (torch.min(var('DISTANCE_m'), torch.tensor(10))**2) \n",
    "              ) \n",
    "        \n",
    "    V_2R_m = (ASC_2R_m_l0 + XB_2R_m\n",
    "              - torch.exp(delta_DIST_2R_m_l0) * torch.min(var('DISTANCE_m'), torch.tensor(25))\n",
    "              + B_DIST_2R2_m_l0 * (torch.min(var('DISTANCE_m'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # women:\n",
    "    XB_TC_w = (torch.tensor(0))\n",
    "\n",
    "    XB_2R_w = (torch.tensor(0))\n",
    "\n",
    "    # example of how heterogeneity can be added to the constant of TWO WHEELS (2R=deux roues) for woman:\n",
    "    # XB_2R_w = (B_AGE40_2R_w_l0 * ((var('AGED_w')-40)/10) \n",
    "    #            + B_AGE40_2R2_w_l0 * (((var('AGED_w')-40)/10)**2))\n",
    "\n",
    "    # ------- Utility functions\n",
    "\n",
    "    V_TC_w = (ASC_TC_w_l0 + XB_TC_w\n",
    "            - torch.exp(delta_TT_TC_w_l0) * torch.min(var('TT_TC_w'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_w_l0 * (torch.min(var('TT_TC_w'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK_w = (-3 * torch.min(var('DISTANCE_w'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_w_l0 * (torch.min(var('DISTANCE_w'), torch.tensor(10))**2) \n",
    "              ) \n",
    "    \n",
    "    V_2R_w = (ASC_2R_w_l0 + XB_2R_w\n",
    "              - torch.exp(delta_DIST_2R_w_l0) * torch.min(var('DISTANCE_w'), torch.tensor(25))\n",
    "              + B_DIST_2R2_w_l0 * (torch.min(var('DISTANCE_w'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # --------------- Men's probabilities\n",
    "    # https://stats.stackexchange.com/questions/304758/softmax-overflow\n",
    "    V_men_stack = torch.stack([V_TC_m[idx_men] / sigma_l0, \n",
    "                            V_WALK_m[idx_men] / sigma_l0, \n",
    "                            V_2R_m[idx_men] / sigma_l0], dim=1)\n",
    "    max_V_men = V_men_stack.max()\n",
    "    exp_V_men = torch.exp(V_men_stack - max_V_men)\n",
    "    sum_exp_men = exp_V_men.sum(dim=1)\n",
    "\n",
    "    P_TC_m, P_WALK_m, P_2R_m = exp_V_men.T / sum_exp_men\n",
    "\n",
    "    # --------------- Women's probabilities\n",
    "    # https://stats.stackexchange.com/questions/304758/softmax-overflow\n",
    "    V_women_stack = torch.stack([V_TC_w[idx_women] / sigma_l0, \n",
    "                            V_WALK_w[idx_women] / sigma_l0, \n",
    "                            V_2R_w[idx_women] / sigma_l0], dim=1)\n",
    "    max_V_women = V_women_stack.max()\n",
    "    exp_V_women = torch.exp(V_women_stack - max_V_women)\n",
    "    sum_exp_women = exp_V_women.sum(dim=1)\n",
    "\n",
    "    P_TC_w, P_WALK_w, P_2R_w = exp_V_women.T / sum_exp_women\n",
    "\n",
    "    # --------------- Choices\n",
    "\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC_m = torch.tensor((choices['COMMUTE_MODE_m']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK_m = torch.tensor((choices['COMMUTE_MODE_m']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_2R_m = torch.tensor((choices['COMMUTE_MODE_m']=='TWO_WHEELS').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    Choice_TC_w = torch.tensor((choices['COMMUTE_MODE_w']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK_w = torch.tensor((choices['COMMUTE_MODE_w']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_2R_w = torch.tensor((choices['COMMUTE_MODE_w']=='TWO_WHEELS').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights_m = var('WEIGHT_m')\n",
    "    weights_m = weights_m[idx_men]\n",
    "    weights_w = var('WEIGHT_w')\n",
    "    weights_w = weights_w[idx_women]\n",
    "    \n",
    "    if null_loglik:\n",
    "\n",
    "        null_LL = torch.sum(weights_m * Choice_TC_m[idx_men] * torch.log(torch.sum(Choice_TC_m[idx_men])/len(idx_men))) + \\\n",
    "            torch.sum(weights_m * Choice_2R_m[idx_men] * torch.log(torch.sum(Choice_2R_m[idx_men])/len(idx_men))) + \\\n",
    "            torch.sum(weights_m * Choice_WALK_m[idx_men] * torch.log(torch.sum(Choice_WALK_m[idx_men])/len(idx_men))) + \\\n",
    "            torch.sum(weights_w * Choice_TC_w[idx_women] * torch.log(torch.sum(Choice_TC_w[idx_women])/len(idx_women))) + \\\n",
    "            torch.sum(weights_w * Choice_2R_w[idx_women] * torch.log(torch.sum(Choice_2R_w[idx_women])/len(idx_women))) + \\\n",
    "            torch.sum(weights_w * Choice_WALK_w[idx_women] * torch.log(torch.sum(Choice_WALK_w[idx_women])/len(idx_women))) \n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "\n",
    "    LL = torch.sum(weights_m * Choice_TC_m[idx_men] * torch.log(torch.clamp(P_TC_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_m * Choice_2R_m[idx_men] * torch.log(torch.clamp(P_2R_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_m * Choice_WALK_m[idx_men] * torch.log(torch.clamp(P_WALK_m, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_TC_w[idx_women] * torch.log(torch.clamp(P_TC_w, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_2R_w[idx_women] * torch.log(torch.clamp(P_2R_w, min=epsilon))) + \\\n",
    "        torch.sum(weights_w * Choice_WALK_w[idx_women] * torch.log(torch.clamp(P_WALK_w, min=epsilon))) \n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS_m = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC_m / sigma_l0) \n",
    "            + torch.exp(V_WALK_m / sigma_l0) + torch.exp(V_2R_m / sigma_l0) \n",
    "        )\n",
    "        LS_w = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC_w / sigma_l0) \n",
    "            + torch.exp(V_WALK_w / sigma_l0) + torch.exp(V_2R_w / sigma_l0) \n",
    "        )\n",
    "        return LS_m, LS_w\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx_men) + len(idx_women)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb20bd",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- The function will stop optimizing after 5000 iterations, you modify it as you wish \n",
    "- You can modify the **gtol** parameter to get more precision on the estimation but \\\n",
    "it will be costly in terms of computation time\n",
    "- If your estimation takes too much time I suggest you to increase the **gtol** by 0.5 \n",
    "\n",
    "### How to estimate :\n",
    "\n",
    "- Run the first estimation by leaving the **initial_values** commented \n",
    "- Then you can see the estimated parameters in the **summary_level0** table \n",
    "- Save the parameters with the **SaveParameters** function => parameters will be saved in the parameters folder that is on the same folder as your code\n",
    "- Then you can add some new variables to your objective function, and start a new estimation with the last parameters as **initial_values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   9%|▊         | 431/5000 [01:26<15:02,  5.07it/s, Objective Value=71188.10487]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:   9%|▊         | 431/5000 [01:29<15:47,  4.82it/s, Objective Value=71188.10487]\n"
     ]
    }
   ],
   "source": [
    "summary_level0, parameters_level0 = Optimize(level0, \n",
    "         prepare_data_level0(df, year=year), \n",
    "        #  initial_values='Level0_CONSTRAINT',\n",
    "         max_iter=5000,\n",
    "         gtol=1,\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level0,\n",
    "               parameters_level0,\n",
    "               excel=True, # if True : this will give you the summary_level0 table in an excel file in the parameters folder \n",
    "               data=prepare_data_level0(df, year=year),\n",
    "               file_name='Level0_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0aaf0f",
   "metadata": {},
   "source": [
    "# Level 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecb895",
   "metadata": {},
   "source": [
    "## Parameter names convention :\n",
    "\n",
    "- for the parameters of the Pareto weight (Lambda) : begin with **L_**\n",
    "- for the parameters of the different constants : begin with **B_**\n",
    "- for the parameters of the value of time : begin with **votCA_** if the value of time of car alone, **votCP_** if car passenger, etc.\n",
    "- the end of each parameter should always follow the rules of each level : so, here each parameter ends with : **_l1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b9c25",
   "metadata": {},
   "source": [
    "### Tips :\n",
    "- Here we start by computing the *logsum* resulting from level 0. Be careful to load the right parameters to compute it \\\n",
    "otherwise you will end up with a wrong *logsum* term \n",
    "- This level is the **hardest to identify** : I recommand you to add variables in the Lambda, \\\n",
    "the constants of OTHERS (being the case of choosing other modes than car), and the VOT of car alone at the same time \n",
    "- *ASC_Cp_m_l1*, *ASC_Cp_w_l1*, *ASC_Cd_m_l1*, *ASC_Cd_w_l1* and \\\n",
    "*delta_Cp_m_l1*, *delta_Cp_w_l1*, *delta_Cd_m_l1*, *delta_Cd_w_l1* are the **hardest to identify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parameters of the final model in level 0 (so the last UNconstraint model that you've estimated)\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level0, \n",
    "                file_name='Level0_UNCONSTRAINT') \n",
    "\n",
    "# this adds the logsums of the man and the woman to the dataset\n",
    "df['LS_m'], df['LS_w'] = level0(loaded_parameters, prepare_data_level0(df, year=year), logsum=True)\n",
    "\n",
    "\n",
    "def level1(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  pareto_weight=False,\n",
    "                  logsum=False,\n",
    "                  utility_nestB=False,\n",
    "                  all_sample=False,\n",
    "                  year=year):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx1 = df[\"all_idx\"]\n",
    "                idx2 = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx1 = df[\"is_one_car_idx\"]\n",
    "                idx2 = df[\"is_multi_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "    \n",
    "        (\n",
    "        sigma_1c_l1, sigma_2c_l1,\n",
    "\n",
    "        ASC_Cp_m_l1, ASC_Cp_w_l1,\n",
    "        ASC_Cd_m_l1, ASC_Cd_w_l1,\n",
    "\n",
    "        ASC_B_w_l1, delta_Ca_w_l1, delta_Cd_w_l1, delta_Cp_w_l1,\n",
    "        ASC_B_m_l1, delta_Ca_m_l1, delta_Cp_m_l1, delta_Cd_m_l1,\n",
    "\n",
    "        ) = params\n",
    "\n",
    "        Xb_Lambda = (torch.tensor(0))\n",
    "\n",
    "        Lambda = 1 / (1 + torch.exp(-Xb_Lambda))\n",
    "\n",
    "        Xb_m_OTHERS = (torch.tensor(0))\n",
    "                       \n",
    "        Xb_w_OTHERS = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CD = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CD = (torch.tensor(0))\n",
    "\n",
    "        # individual vot and utilities:\n",
    "        VOT_Ca_m = torch.exp(delta_Ca_m_l1)\n",
    "        \n",
    "        VOT_Ca_w = torch.exp(delta_Ca_w_l1)\n",
    "\n",
    "        V_Ca_m = -VOT_Ca_m*var('TT_VP_m')\n",
    "        V_Ca_w = -VOT_Ca_w*var('TT_VP_w')\n",
    "\n",
    "        V_Cp_m = (ASC_Cp_m_l1 + Xb_m_CP) - VOT_Ca_m*torch.exp(delta_Cp_m_l1)*var('TT_VP_m') \n",
    "        V_Cp_w = (ASC_Cp_w_l1 + Xb_w_CP) - VOT_Ca_w*torch.exp(delta_Cp_w_l1)*var('TT_VP_w') \n",
    "\n",
    "        V_Cd_m = (ASC_Cd_m_l1 + Xb_m_CD) - VOT_Ca_m*torch.exp(delta_Cd_m_l1)*var('TT_VP_w') - VOT_Ca_m*var('WOMANtowardsMAN')\n",
    "        V_Cd_w = (ASC_Cd_w_l1 + Xb_w_CD) - VOT_Ca_w*torch.exp(delta_Cd_w_l1)*var('TT_VP_m') - VOT_Ca_w*var('MANtowardsWOMAN')\n",
    "\n",
    "        V_B_m = (ASC_B_m_l1 + Xb_m_OTHERS) + var('LS_m')\n",
    "        V_B_w = (ASC_B_w_l1 + Xb_w_OTHERS) + var('LS_w')\n",
    "\n",
    "        # Utilitaires collectifs : (extrait)\n",
    "        V_CaCa = Lambda * V_Ca_w + (1 - Lambda) * V_Ca_m\n",
    "        V_BB = Lambda * V_B_w + (1 - Lambda) * V_B_m\n",
    "        V_CaB = Lambda * V_Ca_w + (1 - Lambda) * V_B_m\n",
    "        V_BCa = Lambda * V_B_w + (1 - Lambda) * V_Ca_m\n",
    "        V_CdCp = Lambda * V_Cd_w + (1 - Lambda) * V_Cp_m\n",
    "        V_CpCd = Lambda * V_Cp_w + (1 - Lambda) * V_Cd_m\n",
    "\n",
    "        # -------- One-car probabilities\n",
    "        V_1c_stack = torch.stack([\n",
    "                V_BB[idx1] / sigma_1c_l1,\n",
    "                V_CaB[idx1] / sigma_1c_l1,\n",
    "                V_BCa[idx1] / sigma_1c_l1,\n",
    "                V_CdCp[idx1] / sigma_1c_l1,\n",
    "                V_CpCd[idx1] / sigma_1c_l1\n",
    "        ], dim=1)\n",
    "        max_V_1c = V_1c_stack.max()\n",
    "        exp_V_1c = torch.exp(V_1c_stack - max_V_1c)\n",
    "        sum_exp_1c = exp_V_1c.sum(dim=1)\n",
    "\n",
    "        P_BB_1c, P_CaB_1c, P_BCa_1c, P_CdCp_1c, P_CpCd_1c = exp_V_1c.T / sum_exp_1c\n",
    "\n",
    "        # -------- Two-car probabilities\n",
    "        V_2c_stack = torch.stack([\n",
    "                V_CaCa[idx2] / sigma_2c_l1,\n",
    "                V_BB[idx2] / sigma_2c_l1,\n",
    "                V_CaB[idx2] / sigma_2c_l1,\n",
    "                V_BCa[idx2] / sigma_2c_l1,\n",
    "                V_CdCp[idx2] / sigma_2c_l1,\n",
    "                V_CpCd[idx2] / sigma_2c_l1\n",
    "        ], dim=1)\n",
    "        max_V_2c = V_2c_stack.max()\n",
    "        exp_V_2c = torch.exp(V_2c_stack - max_V_2c)\n",
    "        sum_exp_2c = exp_V_2c.sum(dim=1)\n",
    "\n",
    "        P_CaCa_2c, P_BB_2c, P_CaB_2c, P_BCa_2c, P_CdCp_2c, P_CpCd_2c = exp_V_2c.T / sum_exp_2c\n",
    "\n",
    "        # -------- Choices\n",
    "        choices = df['df']\n",
    "\n",
    "        if year>2016:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "        else:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "\n",
    "\n",
    "        w_1c = var('WEIGHT_hh')\n",
    "        w_1c = w_1c[idx1]\n",
    "        w_2c = var('WEIGHT_hh')\n",
    "        w_2c = w_2c[idx2]\n",
    "\n",
    "        epsilon = 1e-30\n",
    "\n",
    "        LL_1c = (\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CC)[idx1] * torch.log(torch.clamp(P_CdCp_1c + P_CpCd_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BB)[idx1] * torch.log(torch.clamp(P_BB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CaB)[idx1] * torch.log(torch.clamp(P_CaB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BCa)[idx1] * torch.log(torch.clamp(P_BCa_1c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        LL_2c = (\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CC)[idx2] * torch.log(torch.clamp(P_CaCa_2c + P_CdCp_2c + P_CpCd_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BB)[idx2] * torch.log(torch.clamp(P_BB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CaB)[idx2] * torch.log(torch.clamp(P_CaB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BCa)[idx2] * torch.log(torch.clamp(P_BCa_2c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        if pytorch:\n",
    "                return -(LL_1c + LL_2c)\n",
    "        if df_length:\n",
    "                return len(V_B_w)\n",
    "        \n",
    "        if not pytorch and null_loglik:\n",
    "                n_1c = len(idx1)\n",
    "                n_2c = len(idx2)\n",
    "\n",
    "                if year>2016:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                else:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4 )).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).astype(float).values)\n",
    "\n",
    "                Choice_CC_1c, Choice_BB_1c, Choice_CaB_1c, Choice_BCa_1c = (\n",
    "                Choice_CC[idx1], Choice_BB[idx1], Choice_CaB[idx1], Choice_BCa[idx1])\n",
    "                Choice_CC_2c, Choice_BB_2c, Choice_CaB_2c, Choice_BCa_2c = (\n",
    "                Choice_CC[idx2], Choice_BB[idx2], Choice_CaB[idx2], Choice_BCa[idx2])\n",
    "\n",
    "                # observed shares\n",
    "                share_CC_1c = torch.sum(Choice_CC_1c) / n_1c\n",
    "                share_BB_1c = torch.sum(Choice_BB_1c) / n_1c\n",
    "                share_CaB_1c = torch.sum(Choice_CaB_1c) / n_1c\n",
    "                share_BCa_1c = torch.sum(Choice_BCa_1c) / n_1c\n",
    "\n",
    "                share_CC_2c = torch.sum(Choice_CC_2c) / n_2c\n",
    "                share_BB_2c = torch.sum(Choice_BB_2c) / n_2c\n",
    "                share_CaB_2c = torch.sum(Choice_CaB_2c) / n_2c\n",
    "                share_BCa_2c = torch.sum(Choice_BCa_2c) / n_2c\n",
    "\n",
    "                w_1c = var('WEIGHT_hh')\n",
    "                w_1c = w_1c[idx1]\n",
    "                w_2c = var('WEIGHT_hh')\n",
    "                w_2c = w_2c[idx2]\n",
    "\n",
    "                null_LL_1c = (\n",
    "                torch.sum(w_1c * Choice_CC_1c * torch.log(torch.clamp(share_CC_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BB_1c * torch.log(torch.clamp(share_BB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_CaB_1c * torch.log(torch.clamp(share_CaB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BCa_1c * torch.log(torch.clamp(share_BCa_1c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                null_LL_2c = (\n",
    "                torch.sum(w_2c * Choice_CC_2c * torch.log(torch.clamp(share_CC_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BB_2c * torch.log(torch.clamp(share_BB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_CaB_2c * torch.log(torch.clamp(share_CaB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BCa_2c * torch.log(torch.clamp(share_BCa_2c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                return -(null_LL_1c + null_LL_2c)\n",
    "        \n",
    "        if pareto_weight:\n",
    "                return Lambda\n",
    "        \n",
    "        if logsum:\n",
    "                LS_1c = sigma_1c_l1 * torch.log(\n",
    "                        torch.exp(V_BB/sigma_1c_l1) + torch.exp(V_CaB/sigma_1c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_1c_l1) + torch.exp(V_CpCd/sigma_1c_l1) + torch.exp(V_CdCp/sigma_1c_l1)\n",
    "                )\n",
    "                LS_2c = sigma_2c_l1 * torch.log(\n",
    "                        torch.exp(V_CaCa/sigma_2c_l1) + torch.exp(V_BB/sigma_2c_l1) + torch.exp(V_CaB/sigma_2c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_2c_l1) + torch.exp(V_CpCd/sigma_2c_l1) + torch.exp(V_CdCp/sigma_2c_l1)\n",
    "                )\n",
    "                return (LS_1c).detach().numpy(), (LS_2c).detach().numpy()\n",
    "        if utility_nestB:\n",
    "                return V_BB.detach().numpy()\n",
    "        \n",
    "        return -(LL_1c + LL_2c).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level1, parameters_level1 = Optimize(level1, \n",
    "         prepare_data_level1(df), \n",
    "        #  initial_values='Level1_CONSTRAINT',\n",
    "         max_iter=5000,\n",
    "         gtol=1,\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level1,\n",
    "               parameters_level1,\n",
    "               excel=True,\n",
    "               data=prepare_data_level1(df),\n",
    "               file_name='Level1_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0df9db",
   "metadata": {},
   "source": [
    "# Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['LS_1c'], df['LS_2c'] = level1(loaded_parameters, prepare_data_level1(df), logsum=True)\n",
    "\n",
    "def level2(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  logsum=False,\n",
    "                  all_sample=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx = df[\"at_least_one_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l2,\n",
    "        \n",
    "        ASC_2c_l2) = params\n",
    "\n",
    "        XB_2c = (torch.tensor(0))\n",
    "        \n",
    "        V_1car = var('LS_1c') \n",
    "        V_2car = (ASC_2c_l2 + XB_2c + var('LS_2c')) \n",
    "\n",
    "        # -------- Probabilities\n",
    "        V_stack = torch.stack([\n",
    "                V_1car[idx] / sigma_l2,\n",
    "                V_2car[idx] / sigma_l2\n",
    "        ], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_1car, P_2car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_1CAR = torch.tensor((choice['VOIT'] == 1).astype(int), dtype=torch.float64)\n",
    "        CHOICE_2CAR = torch.tensor((choice['VOIT'] >= 2).astype(int), dtype=torch.float64)\n",
    "\n",
    "        w = var('WEIGHT_hh')\n",
    "        w = w[idx]\n",
    "\n",
    "        epsilon=1e-30\n",
    "        LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.clamp(P_1car, min=epsilon))) +\n",
    "          torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.clamp(P_2car, min=epsilon))))\n",
    "        \n",
    "        if pytorch:\n",
    "                return -LL\n",
    "        \n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.sum(CHOICE_1CAR[idx])/len(idx)))\n",
    "                        + torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.sum(CHOICE_2CAR[idx])/len(idx))))\n",
    "                return -null_LL\n",
    "        \n",
    "        if df_length:\n",
    "                return len(idx)\n",
    "        \n",
    "        if logsum:\n",
    "                LS_level2 = sigma_l2 * torch.log(\n",
    "                        torch.exp(V_1car/sigma_l2) + torch.exp(V_2car/sigma_l2)\n",
    "                )\n",
    "                return (LS_level2).detach().numpy()\n",
    "        \n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level2, parameters_level2 = Optimize(level2, \n",
    "        prepare_data_level2(df), \n",
    "        #  initial_values='Level2_CONSTRAINT',\n",
    "        max_iter=5000,\n",
    "        gtol=1,\n",
    "        display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level2,\n",
    "               parameters_level2,\n",
    "               excel=True,\n",
    "               data=prepare_data_level2(df),\n",
    "               file_name='Level2_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8aa5c8",
   "metadata": {},
   "source": [
    "# Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15251f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level2, \n",
    "                file_name='Level2_UNCONSTRAINT')\n",
    "\n",
    "df['LS_car'] = level2(loaded_parameters, prepare_data_level2(df), logsum=True)\n",
    "\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['V_BB'] = level1(loaded_parameters, prepare_data_level1(df), utility_nestB=True)\n",
    "\n",
    "def level3(params, \n",
    "                df, \n",
    "                pytorch=False, \n",
    "                grad=False, \n",
    "                null_loglik=False, \n",
    "                df_length=False,\n",
    "                logsum=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l3,\n",
    "\n",
    "        ASC_car_l3) = params\n",
    "\n",
    "        XB_car = (torch.tensor(0))\n",
    "\n",
    "        V_NoCar = var('V_BB') \n",
    "        V_Car = ASC_car_l3 + XB_car + var('LS_car')\n",
    "\n",
    "        V_stack = torch.stack([\n",
    "                V_NoCar/sigma_l3, \n",
    "                V_Car/sigma_l3], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_NoCar, P_Car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_NOCAR = torch.tensor((choice['VOIT'] == 0).astype(int), dtype=torch.float64)\n",
    "        CHOICE_CAR = torch.tensor((choice['VOIT'] >= 1).astype(int), dtype=torch.float64)\n",
    "\n",
    "        epsilon=1e-30\n",
    "        w = var('WEIGHT_hh')\n",
    "\n",
    "        LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.clamp(P_NoCar, min=epsilon))) +\n",
    "                torch.sum(w * CHOICE_CAR * torch.log(torch.clamp(P_Car, min=epsilon))))\n",
    "\n",
    "        if pytorch:\n",
    "                return -LL\n",
    "\n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.sum(CHOICE_NOCAR)/len(CHOICE_NOCAR)))\n",
    "                        + torch.sum(w * CHOICE_CAR * torch.log(torch.sum(CHOICE_CAR)/len(CHOICE_CAR))))\n",
    "                return -null_LL\n",
    "\n",
    "        if df_length:\n",
    "                return len(df['df'])\n",
    "\n",
    "        if logsum:\n",
    "                LS_level3 = sigma_l3 * torch.log(\n",
    "                torch.exp(V_NoCar/sigma_l3) + torch.exp(V_Car/sigma_l3)\n",
    "                )\n",
    "                return (LS_level3).detach().numpy()\n",
    "\n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff53e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level3, parameters_level3 = Optimize(level3, \n",
    "         prepare_data_level3(df), \n",
    "        #  initial_values='Level3_CONSTRAINT',\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level3,\n",
    "               parameters_level3,\n",
    "               excel=True,\n",
    "               data=prepare_data_level3(df),\n",
    "               file_name='Level3_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0db95",
   "metadata": {},
   "source": [
    "# Simultaneous estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimultaneousNestLogitModel(params_all, df, null_loglik=False, pytorch=False, grad=False):\n",
    "\n",
    "    # here we need the lenght of the parameters of each level (except the last one)\n",
    "    p0 = len(LoadParameters(level0, 'Level0_UNCONSTRAINT'))\n",
    "    p1 = len(LoadParameters(level1, 'Level1_UNCONSTRAINT'))\n",
    "    p2 = len(LoadParameters(level2, 'Level2_UNCONSTRAINT'))\n",
    "\n",
    "    params0 = params_all[:p0]\n",
    "    params1 = params_all[p0:p0+p1]\n",
    "    params2 = params_all[p0+p1:p0+p1+p2]\n",
    "    params3 = params_all[p0+p1+p2:]\n",
    "\n",
    "    df0 = prepare_data_level0(df)\n",
    "    LS_m, LS_w = level0(params0, df0, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_m'] = LS_m\n",
    "    df['LS_w'] = LS_w\n",
    "\n",
    "    df1 = prepare_data_level1(df)\n",
    "    LS_1c, LS_2c = level1(params1, df1, logsum=True, all_sample=True)\n",
    "    V_BB = level1(params1, df1, utility_nestB=True, all_sample=True)\n",
    "\n",
    "    df['LS_1c'] = LS_1c\n",
    "    df['LS_2c'] = LS_2c\n",
    "\n",
    "    df2 = prepare_data_level2(df)\n",
    "    LS_car = level2(params2, df2, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_car'] = LS_car\n",
    "    df['V_BB'] = V_BB\n",
    "\n",
    "    df3 = prepare_data_level3(df)\n",
    "\n",
    "    LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL3 = level3(params3, df3, pytorch=True, grad=grad)\n",
    "\n",
    "    total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    if null_loglik:\n",
    "        LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL3 = level3(params3, df3, pytorch=True, grad=grad, null_loglik=True)\n",
    "\n",
    "        total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    return total_LL if pytorch else total_LL.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcc579",
   "metadata": {},
   "source": [
    "### Mandatory :\n",
    "\n",
    "- You have to start the simultaneous estimation by using the parameters that you estimated independently on each level \n",
    "- This model is highly non-linear, which means that if you start by random values, it will almost never converge and will stay stuck in a local optima \n",
    "- Also, starting with those *independetly estimated parameters* will save you a lot of time in terms of computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12676793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from independent estimated parameters\n",
    "all_params = torch.cat([\n",
    "    LoadParameters(level0, 'Level0_UNCONSTRAINT'),\n",
    "    LoadParameters(level1, 'Level1_UNCONSTRAINT'),\n",
    "    LoadParameters(level2, 'Level2_UNCONSTRAINT'),\n",
    "    LoadParameters(level3, 'Level3_UNCONSTRAINT')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to start from your simultaneously estimated parameters \n",
    "# But they have to be estimated first, and then saved \n",
    "joint_parameters = JointLoadParameters(\n",
    "    file_name='Joint_UNCONSTRAINT',\n",
    "    level0=level0,\n",
    "    level1=level1,\n",
    "    level2=level2,\n",
    "    level3=level3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = JointOptimize(\n",
    "    func=SimultaneousNestLogitModel, \n",
    "    data=df, \n",
    "    initial_values=all_params, # start from independent estimated parameters\n",
    "    gtol=1,\n",
    "    max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute the summary table (can take some time because the model is big)\n",
    "# between 1 and 2min usually\n",
    "table = JointDisplayResults(\n",
    "               func=SimultaneousNestLogitModel,\n",
    "               params=parameters,\n",
    "               data=df,\n",
    "               level0=level0,\n",
    "               level1=level1,\n",
    "               level2=level2,\n",
    "               level3=level3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JointSaveParameters(params=parameters,\n",
    "                    level0=level0,\n",
    "                    level1=level1,\n",
    "                    level2=level2,\n",
    "                    level3=level3,\n",
    "                    table=table,\n",
    "                    excel=True,\n",
    "                    file_name='Joint_UNCONSTRAINT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
