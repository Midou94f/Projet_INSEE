{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b378c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x).rstrip('0').rstrip('.') if x != 0 else '0')\n",
    "import numpy as np \n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "import polars as pl \n",
    "pl.Config(set_fmt_float=\"full\")\n",
    "pl.Config(tbl_cols=1000)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os \n",
    "import seaborn as sns\n",
    "np.random.seed(22)\n",
    "import torch \n",
    "\n",
    "# Modification ici pour importer les nouvelles fonctions adapt√©es aux c√©libataires\n",
    "from packages.utils2 import Optimize, JointOptimize\n",
    "from packages.utils2 import SaveParameters, LoadParameters, JointDisplayResults, JointSaveParameters, JointLoadParameters\n",
    "# Remplacer par les nouvelles fonctions pour les c√©libataires\n",
    "from packages.utils2 import prepare_data_level0_single, prepare_data_level1_single, prepare_data_level2_single\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9084478",
   "metadata": {},
   "source": [
    "# CODE MODEL - CELIBATAIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a790c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Ann√©e d'√©tude\n",
    "year = 2017\n",
    "\n",
    "# Charger les donn√©es\n",
    "data = pl.read_parquet(f'/Users/mehdifehri/Desktop/Conduite de Projet/Data/single_clean.parquet')\n",
    "\n",
    "# Supprimer les observations intrazonales\n",
    "data = data.filter(pl.col('INTRAZONAL') == 0)\n",
    "\n",
    "# Cr√©er les poids normalis√©s pour tous les c√©libataires\n",
    "data = data.with_columns([\n",
    "    # Poids individuel normalis√©\n",
    "    (pl.col('IPONDI') * (len(data) / pl.col('IPONDI').sum())).alias(\"WEIGHT\")\n",
    "])\n",
    "\n",
    "# Convertir en DataFrame pandas\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bebcb8",
   "metadata": {},
   "source": [
    "# Overall guidelines:\n",
    "\n",
    "- All parameters have to finish their names by _l* with * being the number of the level \\\n",
    "*For example : B_RES_INNERRING_l3 is the parameter of the \"couronne\" of the residential location in level 3*\n",
    "\n",
    "## Steps of estimation :\n",
    "\n",
    "1) Run the constraint model (without explanatory variables) \n",
    "2) Save the parameters of the constraint model, add some heterogeneity to the model \n",
    "3) Estimate again but with the parameters of the constraint model as initial values \n",
    "4) Save the parameters of the UNconstraint model (the one with heterogeneity)\n",
    "5) Add some new variables, estimate with the UNconstraint parameters as initial values\n",
    "6) Do it again until you are satified by your model \n",
    "\n",
    "## Tips :\n",
    "\n",
    "- To access a variable you have to use *var('my_variable')*, with **'my_variable'** being the name of the variable in your dataset \n",
    "- To add a variable with his associated parameter, you can name the parameter as you want (**by always adding the level at the end**) \\\n",
    "*For example : B_DIST_BIKE2_w_l0*var('DISTANCE')**2 \n",
    "- Note that we truncate the DISTANCE, TRAVEL TIME for WALK, BIKE and TC for a purpose of generalization when \\\n",
    "forcasting on different datasets where people could give extreme non-coherent values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc408e",
   "metadata": {},
   "source": [
    "# Level 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c201cbc",
   "metadata": {},
   "source": [
    "### Level 0 guidelines:\n",
    "\n",
    "- **!! IMPORTANT !!** :All parameters have to finish their names with _(gender)_l1 : **\"m\" for man and \"w\" for woman** \\\n",
    "*For example : B_WP_OUTERRING_m_l0 is the parameter of the \"couronne\" of the job location in level 1 for the man, B_WP_OUTERRING_w_l0 for woman*\n",
    "- Except for *sigma_l0* which is the same for the man and the woman\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- To add characteristics in the constant of a mode, you can add them in *XB* \\\n",
    "*For example : adding characteristics into XB_TC_m, is adding heterogeneity in the constant of the mode TC for the man*\n",
    "- To add characteristics in the VOT (value of time) of a mode, you can add them in the *torch.exp(delta_TT_MOTO_m_l0)* term \\\n",
    "For example :\n",
    "```python\n",
    "torch.exp(delta_TT_MOTO_m_l0 + VOT_OCCP_SELFEMPLOYED_MOTO_m_l0 * var('OCCP_SELFEMPLOYED_m')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18535866",
   "metadata": {},
   "source": [
    "### Level 0 function if your year of study is after 2016 (not included)\n",
    "\n",
    "- There is two different function for level 0 depending on the year of study : \\\n",
    "it is only after 2017 that INSEE has splitted MOTO and BIKE from the TWO WHEELS alternative. \\\n",
    "- So from 2017 there are 4 choices at the level 0 (BIKE, MOTO, TC and WALK), and before that \\\n",
    "there are 3 choices (TC, WALK and TWO WHEELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2a3d2",
   "metadata": {},
   "source": [
    "# Sp√©cificit√© de l'√©chantillon √©tudi√© : les c√©libataires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236dd62",
   "metadata": {},
   "source": [
    "Pour les c√©libataires, nous n'avons plus besoin du niveau 3 du mod√®le pour plusieurs raisons :\n",
    "\n",
    "Structure simplifi√©e : Dans le mod√®le complet pour les couples bi-actifs, le niveau 3 repr√©sente le choix d'achat de la premi√®re voiture sp√©cifiquement pour les couples bi-actifs. C'est une d√©cision distincte de l'achat d'une deuxi√®me voiture.\n",
    "D√©cision unique pour les c√©libataires : Pour un c√©libataire, il n'y a qu'une seule d√©cision d'achat de voiture √† mod√©liser - poss√©der ou non une voiture. Il n'y a pas de distinction entre \"premi√®re\" et \"deuxi√®me\" voiture comme pour les couples.\n",
    "Mod√®le √† 3 niveaux pour les c√©libataires :\n",
    "\n",
    "Niveau 0 : Choix du mode de transport (marche, v√©lo, moto, transports en commun)\n",
    "Niveau 1 : Choix entre voiture et autres modes quand on a une voiture\n",
    "Niveau 2 : D√©cision d'achat d'une voiture (oui/non)\n",
    "\n",
    "\n",
    "\n",
    "En contraste, le mod√®le pour les couples bi-actifs a 4 niveaux car il doit g√©rer des choix conjoints plus complexes et la possibilit√© d'avoir 0, 1 ou 2+ voitures.\n",
    "Cette simplification est logique et refl√®te bien la r√©alit√© des c√©libataires, qui font face √† des d√©cisions moins complexes en mati√®re de possession et d'utilisation de voiture par rapport aux couples, o√π les choix doivent √™tre coordonn√©s entre deux personnes.R√©essayerClaude peut faire des erreurs. Assurez-vous de v√©rifier ses r√©ponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c47012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_C(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les c√©libataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,  \n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # ----------- Fonctions d'utilit√© (une seule s√©rie pour tous les c√©libataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 \n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 \n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 \n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilit√©s (une seule s√©rie pour tous les c√©libataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule s√©rie pour tous les c√©libataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule s√©rie pour tous les c√©libataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22634ee",
   "metadata": {},
   "source": [
    "## Principaux changements effectu√©s:\n",
    "\n",
    "- Renomm√© la fonction en level0_single (au lieu de level0_singles)\n",
    "- Remplac√© les indices s√©par√©s pour hommes/femmes par un seul indice level0_idx\n",
    "- Supprim√© les suffixes _m et _w des param√®tres\n",
    "- Ajout√© des param√®tres pour l'effet du genre (B_GENDER_*)\n",
    "- Cr√©√© une variable indicatrice GENDER_DUMMY bas√©e sur SEXE\n",
    "- Unifi√© toutes les fonctions d'utilit√©, probabilit√©s et calculs de log-likelihood\n",
    "- Dans logsum, retourne une seule s√©rie au lieu de deux (LS_m, LS_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb20bd",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- The function will stop optimizing after 5000 iterations, you modify it as you wish \n",
    "- You can modify the **gtol** parameter to get more precision on the estimation but \\\n",
    "it will be costly in terms of computation time\n",
    "- If your estimation takes too much time I suggest you to increase the **gtol** by 0.5 \n",
    "\n",
    "### How to estimate :\n",
    "\n",
    "- Run the first estimation by leaving the **initial_values** commented \n",
    "- Then you can see the estimated parameters in the **summary_level0** table \n",
    "- Save the parameters with the **SaveParameters** function => parameters will be saved in the parameters folder that is on the same folder as your code\n",
    "- Then you can add some new variables to your objective function, and start a new estimation with the last parameters as **initial_values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85789a29",
   "metadata": {},
   "source": [
    "# Estimation des param√®tres contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ca60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 657/1500 [12:00<11:45,  1.20it/s, Objective Value=50290.19500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 657/1500 [12:04<15:29,  1.10s/it, Objective Value=50290.19500]\n"
     ]
    }
   ],
   "source": [
    "summary_level0, parameters_level0 = Optimize(\n",
    "    level0_single_C, \n",
    "    prepare_data_level0_single(df, year=2017), \n",
    "    max_iter=1500,\n",
    "    gtol=1,\n",
    "    display_results=True\n",
    ")\n",
    "\n",
    "# Sauvegarde des param√®tres\n",
    "SaveParameters(\n",
    "    level0_single_C,\n",
    "    parameters_level0,  # L√† c'est bien le tensor\n",
    "    excel=False,\n",
    "    data=prepare_data_level0_single(df, year=2017),\n",
    "    file_name='Level0_CONSTRAINT'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f1ef5",
   "metadata": {},
   "source": [
    "#  Analyse et interpr√©tation du mod√®le contraint ‚Äì Choix modal des c√©libataires\n",
    "\n",
    "##  Vue d'ensemble\n",
    "\n",
    "Le mod√®le estim√© est un mod√®le de choix discret (logit multinomial) pour les d√©cisions de transport des **c√©libataires**, avec quatre alternatives :\n",
    "- **TC** (Transports en commun),\n",
    "- **Marche**,\n",
    "- **Moto**,\n",
    "- **V√©lo**.\n",
    "\n",
    " **Attention : le mod√®le n‚Äôa pas converg√©**. Cela signifie que l‚Äôoptimisation n‚Äôa pas atteint un vrai minimum. Les r√©sultats peuvent √™tre interpr√©t√©s avec **prudence**.\n",
    "\n",
    "---\n",
    "\n",
    "##  Interpr√©tation des param√®tres cl√©s\n",
    "\n",
    "###  Param√®tre d‚Äô√©chelle\n",
    "\n",
    "- `sigma_l0 = 6.46`  \n",
    "‚Üí Valeur √©lev√©e ‚áí **forte h√©t√©rog√©n√©it√© non observ√©e** dans les comportements de choix.  \n",
    "‚Üí Le mod√®le ne capte pas encore bien les diff√©rences individuelles (√¢ge, genre, revenu‚Ä¶).\n",
    "\n",
    "---\n",
    "\n",
    "### Constantes modales (ASC)\n",
    "\n",
    "| Coefficient        | Interpr√©tation |\n",
    "|--------------------|----------------|\n",
    "| `ASC_TC_l0 = 1.88`  | Pr√©f√©rence intrins√®que **positive** pour le TC (vs. marche). |\n",
    "| `ASC_BIKE_l0 = -4.20` | Aversion significative pour le v√©lo. |\n",
    "| `ASC_MOTO_l0 = -14.25` | Tr√®s forte aversion pour la moto. |\n",
    "\n",
    "‚û°Ô∏è Ces ASC mesurent la pr√©f√©rence **structurelle**, toutes choses √©gales par ailleurs, pour chaque mode par rapport √† la r√©f√©rence (ici, **marche**).\n",
    "\n",
    "---\n",
    "\n",
    "### Sensibilit√© au temps de trajet\n",
    "\n",
    "| Coefficient               | Interpr√©tation |\n",
    "|---------------------------|----------------|\n",
    "| `delta_TT_TC_l0 = -3.84`  | TC : l‚Äôutilit√© diminue avec le temps, mais √† un **taux d√©croissant** (transformation exponentielle). |\n",
    "| `delta_TT_MOTO_l0 = 2.91` | **Contre-intuitif** : indiquerait une pr√©f√©rence pour des trajets moto plus longs. Peut signaler : erreur, multicolin√©arit√©, ou biais d‚Äôidentification. |\n",
    "| `B_TT_TC2_l0 = -2.86`     | TC : effet quadratique n√©gatif ‚áí l‚Äôutilit√© **baisse plus vite** avec le temps. |\n",
    "| `B_TT_MOTO2_l0 = -0.77`   | Moto : idem, effet n√©gatif en cas de long trajet. |\n",
    "\n",
    "---\n",
    "\n",
    "### Sensibilit√© √† la distance\n",
    "\n",
    "| Coefficient                   | Interpr√©tation |\n",
    "|-------------------------------|----------------|\n",
    "| `delta_DIST_BIKE_l0 = 1.17`   | **Contre-intuitif** : utilit√© augmente avec la distance √† v√©lo. Peut indiquer que seuls les cyclistes endurants restent. |\n",
    "| `B_DIST_BIKE2_l0 = 0.07`      | Effet quadratique **faiblement positif**. |\n",
    "| `B_DIST_WALK2_l0 = -0.06`     | L‚Äôutilit√© de la marche diminue rapidement avec la distance (effet attendu). |\n",
    "\n",
    "---\n",
    "\n",
    "## Limites et r√©serves\n",
    "\n",
    "1. **Pas de convergence**  \n",
    "   ‚áí Interpr√©tation des coefficients √† faire **avec prudence**.\n",
    "\n",
    "2. **Param√®tres contre-intuitifs**  \n",
    "   - `delta_TT_MOTO_l0` et `delta_DIST_BIKE_l0` ont des **signes inattendus**.\n",
    "   - Possibles causes :\n",
    "     - Variables importantes manquantes,\n",
    "     - Multicolin√©arit√©,\n",
    "     - Mauvais point de d√©part.\n",
    "\n",
    "3. **H√©t√©rog√©n√©it√© non observ√©e importante**  \n",
    "   - `sigma_l0` √©lev√© = **beaucoup de variations** dans les comportements, **pas encore expliqu√©es** par les variables actuelles.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Recommandations\n",
    "\n",
    "1. **Augmenter `max_iter`**  \n",
    "   Pour forcer l‚Äôoptimisation √† aller plus loin et esp√©rer la convergence.\n",
    "\n",
    "2. **Enrichir le mod√®le**\n",
    "   Ajouter :\n",
    "   - Variables socio-d√©mographiques (`AGED`, `SEXE`, `SANI`, `SURF`, etc.),\n",
    "   - Conditions de mobilit√© (`VOIT`, `GARL`, etc.),\n",
    "   - Statut (`ETUD`, `OCCP_*`, etc.).\n",
    "\n",
    "3. **Revoir la sp√©cification fonctionnelle**  \n",
    "   Tester diff√©rentes transformations (log, racine, lin√©aire) pour :\n",
    "   - `DISTANCE`,\n",
    "   - `TT`,\n",
    "   - etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Pourquoi partir du mod√®le contraint ?\n",
    "\n",
    "Utiliser les param√®tres estim√©s **contraints** comme point de d√©part du mod√®le enrichi est **la bonne pratique** :\n",
    "\n",
    "| Avantage | D√©tail |\n",
    "|----------|--------|\n",
    "| üîÅ Stabilit√© | L‚Äôoptimisation d√©marre d‚Äôun **point √©conomiquement r√©aliste**. |\n",
    "| ‚è±Ô∏è Gain de temps | Moins d‚Äôit√©rations n√©cessaires. |\n",
    "| üìä Comparabilit√© | Chaque version enrichie reste **coh√©rente avec la base**, facilitant l‚Äôanalyse des √©carts. |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Conclusion\n",
    "\n",
    "Ce mod√®le contraint constitue une **base solide**. Bien qu‚Äôimparfait, il r√©v√®le d√©j√† certaines tendances et ouvre la voie √† une **mod√©lisation plus fine** de la mobilit√© des c√©libataires par l‚Äôajout d‚Äôh√©t√©rog√©n√©it√© observ√©e.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ace2c",
   "metadata": {},
   "source": [
    "# Estimation des param√®tres non-contraints (mod√®le enrichit d'h√©t√©rog√©n√©it√©)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb9e1d",
   "metadata": {},
   "source": [
    "## Strat√©gie d‚Äôenrichissement du mod√®le non contraint ‚Äì Niveau 0 (C√©libataires)\n",
    "\n",
    "### Objectif\n",
    "Obtenir un mod√®le nested logit **convergent**, **interpr√©table √©conomiquement**, et **statistiquement robuste**, en partant d‚Äôune sp√©cification simple puis en ajoutant progressivement des variables explicatives issues du fichier `single_clean.parquet`.\n",
    "\n",
    "---\n",
    "\n",
    "###  √âtape 0 ‚Äì Mod√®le contraint de base\n",
    "- **Variables int√©gr√©es** : `TT_TC`, `FREEFLOW_TT`, `DISTANCE`, constantes ASC par mode (`ASC_MOTO`, `ASC_BIKE`, `ASC_TC`), et effets quadratiques.\n",
    "- **Hypoth√®se** : comportement modal homog√®ne, pas d‚Äôh√©t√©rog√©n√©it√© interindividuelle.\n",
    "- **But** : obtenir une premi√®re estimation stable (Level0_CONSTRAINT).\n",
    "\n",
    "---\n",
    "\n",
    "### √âtape 1 ‚Äì Genre (`SEXE`)\n",
    "- **Justification** : les pr√©f√©rences modales peuvent varier selon le genre (ex. s√©curit√©, effort physique, normes sociales).\n",
    "- **Impl√©mentation** :\n",
    "  - Ajout de `GENDER_DUMMY = 1 si femme`,\n",
    "  - Param√®tres `B_GENDER_TC`, `B_GENDER_MOTO`, `B_GENDER_BIKE`.\n",
    "\n",
    "---\n",
    "###  √âtape 2 ‚Äì H√©t√©rog√©n√©it√© par √¢ge (`AGED`)\n",
    "\n",
    "#### üîç Justification :\n",
    "- L‚Äô√¢ge affecte les pr√©f√©rences modales : mobilit√© physique, tol√©rance au temps de trajet, pr√©f√©rence pour la marche ou la voiture.\n",
    "- C‚Äôest une variable continue structurante du comportement.\n",
    "\n",
    "#### ‚úÖ Impl√©mentation :\n",
    "- Ajouter `AGED` centr√© (ex : `(AGED - 40)/10`) et son carr√© dans les `XB_*` des utilit√©s.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ú √âtape 3 ‚Äì H√©t√©rog√©n√©it√© socio-√©conomique\n",
    "\n",
    "#### üîç Justification :\n",
    "- Pour capturer les diff√©rences de ressources, d‚Äôacc√®s aux modes, de contraintes et de pr√©f√©rences modales.\n",
    "\n",
    "####  Variables propos√©es :\n",
    "- `SANI` : √©quipement sanitaire (0 = tr√®s pr√©caire ‚Üí 2 = standard), **proxy de pauvret√© mat√©rielle**.\n",
    "- `SURF` : superficie du logement (en classes), **proxy de richesse immobili√®re**.\n",
    "- `HOMEOWNERSHIP` : statut d‚Äôoccupation (1 = propri√©taire, autres = locataire), **proxy de stabilit√© √©conomique**.\n",
    "- `VOIT` : nombre de voitures dans le m√©nage, indicateur **d‚Äôacc√®s √† la voiture priv√©e**.\n",
    "- `GARL` : place de stationnement disponible.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ú √âtape 4 ‚Äì H√©t√©rog√©n√©it√© d√©mographique\n",
    "\n",
    "#### üîç Justification :\n",
    "- Composition du m√©nage influence les contraintes et pr√©f√©rences :\n",
    "  - enfants ‚Üí contraintes horaires,\n",
    "  - grande taille ‚Üí pr√©f√©rence pour modes confortables.\n",
    "\n",
    "####  Variables propos√©es :\n",
    "- `NENFR` : nombre d‚Äôenfants dans le m√©nage,\n",
    "- `NPERR` : nombre total de personnes dans le m√©nage.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ú √âtape 5 ‚Äì √âtudiants (`ETUD`)\n",
    "\n",
    "#### üîç Justification :\n",
    "- Les √©tudiants ont des contraintes et pr√©f√©rences sp√©cifiques :\n",
    "  - Moins d‚Äôacc√®s √† la voiture,\n",
    "  - Pr√©f√©rence pour TC ou marche,\n",
    "  - Moindre valeur du temps.\n",
    "\n",
    "####  Impl√©mentation :\n",
    "- Cr√©er une dummy `IS_STUDENT = 1` si `ETUD == 1`.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ú √âtape 6 ‚Äì Occupation professionnelle (`OCCP_*`)\n",
    "\n",
    "#### üîç Justification :\n",
    "- Statut professionnel structurant :\n",
    "  - `OCCP_EMPLOYEE` / `OCCP_BLUE_COLLAR` ‚Üí effets de distance et co√ªt,\n",
    "  - `OCCP_SELF_EMPLOYED` ‚Üí flexibilit√© horaire,\n",
    "  - `OCCP_WHITE_COLLAR`, `OCCP_PROFESSIONAL` ‚Üí accessibilit√© modale diff√©rente.\n",
    "\n",
    "####  Impl√©mentation :\n",
    "- Ajouter des effets sp√©cifiques dans les `XB_*` selon la cat√©gorie dominante.\n",
    "\n",
    "---\n",
    "\n",
    "### ü™ú √âtape 7 ‚Äì Effet spatial (zones g√©ographiques)\n",
    "\n",
    "#### üîç Justification :\n",
    "- Lieu de r√©sidence et de travail = **fort d√©terminant structurel** du comportement modal.\n",
    "\n",
    "####  Variables propos√©es :\n",
    "- R√©sidence : `RES_PARIS`, `RES_INNERRING`, `RES_OUTERRING`,\n",
    "- Travail : `WP_PARIS`, `WP_INNERRING`, `WP_OUTERRING`.\n",
    "\n",
    "---\n",
    "\n",
    "### M√©thodologie √† chaque √©tape :\n",
    "\n",
    "1. Ajouter les variables dans les `XB_*` de la fonction `level0_single_NC`,\n",
    "2. Ajouter les coefficients correspondants dans `params = (...)`,\n",
    "3. Relancer l‚Äôestimation avec `initial_values='Level0_CONSTRAINT'`,\n",
    "4. Sauvegarder les r√©sultats sous `\"Level0_UNCONSTRAINT_ETAPE_X\"`,\n",
    "5. V√©rifier :\n",
    "   - Convergence,\n",
    "   - Signifiance des coefficients,\n",
    "   - Interpr√©tabilit√© √©conomique.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Objectif final :\n",
    "Un mod√®le :\n",
    "- convergent (log-likelihood stable),\n",
    "- √©conomiquement coh√©rent,\n",
    "- interpr√©table (signes attendus),\n",
    "- utilisable pour pr√©diction ou comparaison avec les couples monoactifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831968e8",
   "metadata": {},
   "source": [
    "# Mod√®le non-contraint enrichit : Test avec 'GENRE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6ccc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_NC1(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les c√©libataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,  \n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0,\n",
    "    \n",
    "    B_GENDER_TC_l0,\n",
    "    B_GENDER_MOTO_l0,\n",
    "    B_GENDER_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # Indicatrice de genre: 1 si femme (SEXE=2), 0 si homme (SEXE=1)\n",
    "    GENDER_DUMMY = (var('SEXE') == 2).float()\n",
    "\n",
    "    # Constantes avec effet du genre\n",
    "    XB_TC = B_GENDER_TC_l0 * GENDER_DUMMY\n",
    "    XB_MOTO = B_GENDER_MOTO_l0 * GENDER_DUMMY\n",
    "    XB_BIKE = B_GENDER_BIKE_l0 * GENDER_DUMMY\n",
    "\n",
    "    # ----------- Fonctions d'utilit√© (une seule s√©rie pour tous les c√©libataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 + XB_TC\n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 + XB_MOTO\n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 + XB_BIKE\n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilit√©s (une seule s√©rie pour tous les c√©libataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule s√©rie pour tous les c√©libataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule s√©rie pour tous les c√©libataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be908b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  29%|‚ñà‚ñà‚ñâ       | 145/500 [01:33<03:48,  1.55it/s, Objective Value=47536.62786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/mehdifehri/Desktop/Conduite de Projet/Code/packages')\n",
    "\n",
    "from utils2 import Optimize, prepare_data_level0_single, SaveParameters\n",
    "\n",
    "# Version correcte avec display_results=False\n",
    "parameters_level0 = Optimize(level0_single_NC1, \n",
    "         prepare_data_level0_single(df, year=2017),\n",
    "         initial_values='Level0_CONSTRAINT',\n",
    "         max_iter=500,\n",
    "         gtol=1,\n",
    "         display_results=False)  # Quand c'est False, la fonction ne renvoie que les param√®tres\n",
    "\n",
    "# Sauvegarde des param√®tres\n",
    "SaveParameters(level0_single_NC1,\n",
    "              parameters_level0,\n",
    "              excel=False,  # False pour √©viter l'erreur de la matrice hessienne\n",
    "              data=prepare_data_level0_single(df, year=2017),\n",
    "              file_name='Level0_NC1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a9b0a",
   "metadata": {},
   "source": [
    "Le model est convergent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72affe5",
   "metadata": {},
   "source": [
    "# Etape 2 : test variable 'Age + Age^2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96de2a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_NC2(params, \n",
    "                     df,\n",
    "                     pytorch=False, \n",
    "                     null_loglik=False, \n",
    "                     grad=False, \n",
    "                     logsum=False,\n",
    "                     df_length=False,\n",
    "                     all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les c√©libataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,\n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0,\n",
    "    \n",
    "    B_GENDER_TC_l0,\n",
    "    B_GENDER_MOTO_l0,\n",
    "    B_GENDER_BIKE_l0,\n",
    "    \n",
    "    B_AGE_TC_l0,\n",
    "    B_AGE_MOTO_l0,\n",
    "    B_AGE_BIKE_l0,\n",
    "    \n",
    "    B_AGE2_TC_l0,\n",
    "    B_AGE2_MOTO_l0,\n",
    "    B_AGE2_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # Indicatrice de genre: 1 si femme (SEXE=2), 0 si homme (SEXE=1)\n",
    "    GENDER_DUMMY = (var('SEXE') == 2).float()\n",
    "    \n",
    "    # Variable d'√¢ge (normalis√©e pour √©viter les probl√®mes num√©riques)\n",
    "    AGE = var('AGED') - 40  # Centrer autour de 40 ans\n",
    "    AGE2 = AGE**2 / 100     # Mettre √† l'√©chelle pour √©viter des valeurs trop grandes\n",
    "\n",
    "    # Constantes avec effet du genre et de l'√¢ge\n",
    "    XB_TC = (B_GENDER_TC_l0 * GENDER_DUMMY + \n",
    "             B_AGE_TC_l0 * AGE + \n",
    "             B_AGE2_TC_l0 * AGE2)\n",
    "    \n",
    "    XB_MOTO = (B_GENDER_MOTO_l0 * GENDER_DUMMY + \n",
    "               B_AGE_MOTO_l0 * AGE + \n",
    "               B_AGE2_MOTO_l0 * AGE2)\n",
    "    \n",
    "    XB_BIKE = (B_GENDER_BIKE_l0 * GENDER_DUMMY + \n",
    "               B_AGE_BIKE_l0 * AGE + \n",
    "               B_AGE2_BIKE_l0 * AGE2)\n",
    "\n",
    "    # ----------- Fonctions d'utilit√© (une seule s√©rie pour tous les c√©libataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 + XB_TC\n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 + XB_MOTO\n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 + XB_BIKE\n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilit√©s (une seule s√©rie pour tous les c√©libataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule s√©rie pour tous les c√©libataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule s√©rie pour tous les c√©libataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f0b608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  37%|‚ñà‚ñà‚ñà‚ñã      | 186/500 [02:14<03:46,  1.38it/s, Objective Value=47388.46652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/mehdifehri/Desktop/Conduite de Projet/Code/packages')\n",
    "\n",
    "from utils2 import Optimize, prepare_data_level0_single, SaveParameters\n",
    "\n",
    "# Version correcte avec display_results=False\n",
    "parameters_level0 = Optimize(level0_single_NC2, \n",
    "         prepare_data_level0_single(df, year=2017),\n",
    "         initial_values='Level0_NC1',\n",
    "         max_iter=500,\n",
    "         gtol=1,\n",
    "         display_results=False)  # Quand c'est False, la fonction ne renvoie que les param√®tres\n",
    "\n",
    "# Sauvegarde des param√®tres\n",
    "SaveParameters(level0_single_NC2,\n",
    "              parameters_level0,\n",
    "              excel=False,  # False pour √©viter l'erreur de la matrice hessienne\n",
    "              data=prepare_data_level0_single(df, year=2017),\n",
    "              file_name='Level0_NC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239a1f3",
   "metadata": {},
   "source": [
    "Il est g√©n√©ralement plus efficace d'utiliser les param√®tres obtenus √† l'√©tape pr√©c√©dente, c'est-√†-dire ceux du mod√®le non contraint pr√©c√©dent (celui avec √¢ge et genre).\n",
    "Il y a plusieurs raisons √† cela:\n",
    "\n",
    "Continuit√© des param√®tres: Les param√®tres des variables d√©j√† incluses (√¢ge, genre) auront des valeurs proches de celles estim√©es pr√©c√©demment, ce qui facilite la convergence.\n",
    "Stabilit√© num√©rique: Partir des estimations pr√©c√©dentes vous place d√©j√† dans une r√©gion \"probable\" de l'espace des param√®tres, r√©duisant les risques de divergence.\n",
    "D√©marche progressive: Cela s'inscrit dans une logique d'enrichissement progressif o√π chaque mod√®le est une extension du pr√©c√©dent.\n",
    "\n",
    "Votre approche serait donc:\n",
    "\n",
    "Mod√®le contraint (base) ‚Üí valeurs initiales pour mod√®le avec √¢ge et genre\n",
    "Mod√®le avec √¢ge et genre ‚Üí valeurs initiales pour mod√®le avec √¢ge, genre et variables socio-√©conomiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a446a",
   "metadata": {},
   "source": [
    "# Etape 2 : test variables socio-√©conomiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0aaf0f",
   "metadata": {},
   "source": [
    "# Level 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86115c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ecb895",
   "metadata": {},
   "source": [
    "## Parameter names convention :\n",
    "\n",
    "- for the parameters of the Pareto weight (Lambda) : begin with **L_**\n",
    "- for the parameters of the different constants : begin with **B_**\n",
    "- for the parameters of the value of time : begin with **votCA_** if the value of time of car alone, **votCP_** if car passenger, etc.\n",
    "- the end of each parameter should always follow the rules of each level : so, here each parameter ends with : **_l1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b9c25",
   "metadata": {},
   "source": [
    "### Tips :\n",
    "- Here we start by computing the *logsum* resulting from level 0. Be careful to load the right parameters to compute it \\\n",
    "otherwise you will end up with a wrong *logsum* term \n",
    "- This level is the **hardest to identify** : I recommand you to add variables in the Lambda, \\\n",
    "the constants of OTHERS (being the case of choosing other modes than car), and the VOT of car alone at the same time \n",
    "- *ASC_Cp_m_l1*, *ASC_Cp_w_l1*, *ASC_Cd_m_l1*, *ASC_Cd_w_l1* and \\\n",
    "*delta_Cp_m_l1*, *delta_Cp_w_l1*, *delta_Cd_m_l1*, *delta_Cd_w_l1* are the **hardest to identify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parameters of the final model in level 0 (so the last UNconstraint model that you've estimated)\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level0, \n",
    "                file_name='Level0_UNCONSTRAINT') \n",
    "\n",
    "# this adds the logsums of the man and the woman to the dataset\n",
    "df['LS_m'], df['LS_w'] = level0(loaded_parameters, prepare_data_level0(df, year=year), logsum=True)\n",
    "\n",
    "\n",
    "def level1(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  pareto_weight=False,\n",
    "                  logsum=False,\n",
    "                  utility_nestB=False,\n",
    "                  all_sample=False,\n",
    "                  year=year):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx1 = df[\"all_idx\"]\n",
    "                idx2 = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx1 = df[\"is_one_car_idx\"]\n",
    "                idx2 = df[\"is_multi_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "    \n",
    "        (\n",
    "        sigma_1c_l1, sigma_2c_l1,\n",
    "\n",
    "        ASC_Cp_m_l1, ASC_Cp_w_l1,\n",
    "        ASC_Cd_m_l1, ASC_Cd_w_l1,\n",
    "\n",
    "        ASC_B_w_l1, delta_Ca_w_l1, delta_Cd_w_l1, delta_Cp_w_l1,\n",
    "        ASC_B_m_l1, delta_Ca_m_l1, delta_Cp_m_l1, delta_Cd_m_l1,\n",
    "\n",
    "        ) = params\n",
    "\n",
    "        Xb_Lambda = (torch.tensor(0))\n",
    "\n",
    "        Lambda = 1 / (1 + torch.exp(-Xb_Lambda))\n",
    "\n",
    "        Xb_m_OTHERS = (torch.tensor(0))\n",
    "                       \n",
    "        Xb_w_OTHERS = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CD = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CD = (torch.tensor(0))\n",
    "\n",
    "        # individual vot and utilities:\n",
    "        VOT_Ca_m = torch.exp(delta_Ca_m_l1)\n",
    "        \n",
    "        VOT_Ca_w = torch.exp(delta_Ca_w_l1)\n",
    "\n",
    "        V_Ca_m = -VOT_Ca_m*var('TT_VP_m')\n",
    "        V_Ca_w = -VOT_Ca_w*var('TT_VP_w')\n",
    "\n",
    "        V_Cp_m = (ASC_Cp_m_l1 + Xb_m_CP) - VOT_Ca_m*torch.exp(delta_Cp_m_l1)*var('TT_VP_m') \n",
    "        V_Cp_w = (ASC_Cp_w_l1 + Xb_w_CP) - VOT_Ca_w*torch.exp(delta_Cp_w_l1)*var('TT_VP_w') \n",
    "\n",
    "        V_Cd_m = (ASC_Cd_m_l1 + Xb_m_CD) - VOT_Ca_m*torch.exp(delta_Cd_m_l1)*var('TT_VP_w') - VOT_Ca_m*var('WOMANtowardsMAN')\n",
    "        V_Cd_w = (ASC_Cd_w_l1 + Xb_w_CD) - VOT_Ca_w*torch.exp(delta_Cd_w_l1)*var('TT_VP_m') - VOT_Ca_w*var('MANtowardsWOMAN')\n",
    "\n",
    "        V_B_m = (ASC_B_m_l1 + Xb_m_OTHERS) + var('LS_m')\n",
    "        V_B_w = (ASC_B_w_l1 + Xb_w_OTHERS) + var('LS_w')\n",
    "\n",
    "        # Utilitaires collectifs : (extrait)\n",
    "        V_CaCa = Lambda * V_Ca_w + (1 - Lambda) * V_Ca_m\n",
    "        V_BB = Lambda * V_B_w + (1 - Lambda) * V_B_m\n",
    "        V_CaB = Lambda * V_Ca_w + (1 - Lambda) * V_B_m\n",
    "        V_BCa = Lambda * V_B_w + (1 - Lambda) * V_Ca_m\n",
    "        V_CdCp = Lambda * V_Cd_w + (1 - Lambda) * V_Cp_m\n",
    "        V_CpCd = Lambda * V_Cp_w + (1 - Lambda) * V_Cd_m\n",
    "\n",
    "        # -------- One-car probabilities\n",
    "        V_1c_stack = torch.stack([\n",
    "                V_BB[idx1] / sigma_1c_l1,\n",
    "                V_CaB[idx1] / sigma_1c_l1,\n",
    "                V_BCa[idx1] / sigma_1c_l1,\n",
    "                V_CdCp[idx1] / sigma_1c_l1,\n",
    "                V_CpCd[idx1] / sigma_1c_l1\n",
    "        ], dim=1)\n",
    "        max_V_1c = V_1c_stack.max()\n",
    "        exp_V_1c = torch.exp(V_1c_stack - max_V_1c)\n",
    "        sum_exp_1c = exp_V_1c.sum(dim=1)\n",
    "\n",
    "        P_BB_1c, P_CaB_1c, P_BCa_1c, P_CdCp_1c, P_CpCd_1c = exp_V_1c.T / sum_exp_1c\n",
    "\n",
    "        # -------- Two-car probabilities\n",
    "        V_2c_stack = torch.stack([\n",
    "                V_CaCa[idx2] / sigma_2c_l1,\n",
    "                V_BB[idx2] / sigma_2c_l1,\n",
    "                V_CaB[idx2] / sigma_2c_l1,\n",
    "                V_BCa[idx2] / sigma_2c_l1,\n",
    "                V_CdCp[idx2] / sigma_2c_l1,\n",
    "                V_CpCd[idx2] / sigma_2c_l1\n",
    "        ], dim=1)\n",
    "        max_V_2c = V_2c_stack.max()\n",
    "        exp_V_2c = torch.exp(V_2c_stack - max_V_2c)\n",
    "        sum_exp_2c = exp_V_2c.sum(dim=1)\n",
    "\n",
    "        P_CaCa_2c, P_BB_2c, P_CaB_2c, P_BCa_2c, P_CdCp_2c, P_CpCd_2c = exp_V_2c.T / sum_exp_2c\n",
    "\n",
    "        # -------- Choices\n",
    "        choices = df['df']\n",
    "\n",
    "        if year>2016:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "        else:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "\n",
    "\n",
    "        w_1c = var('WEIGHT_hh')\n",
    "        w_1c = w_1c[idx1]\n",
    "        w_2c = var('WEIGHT_hh')\n",
    "        w_2c = w_2c[idx2]\n",
    "\n",
    "        epsilon = 1e-30\n",
    "\n",
    "        LL_1c = (\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CC)[idx1] * torch.log(torch.clamp(P_CdCp_1c + P_CpCd_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BB)[idx1] * torch.log(torch.clamp(P_BB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CaB)[idx1] * torch.log(torch.clamp(P_CaB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BCa)[idx1] * torch.log(torch.clamp(P_BCa_1c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        LL_2c = (\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CC)[idx2] * torch.log(torch.clamp(P_CaCa_2c + P_CdCp_2c + P_CpCd_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BB)[idx2] * torch.log(torch.clamp(P_BB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CaB)[idx2] * torch.log(torch.clamp(P_CaB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BCa)[idx2] * torch.log(torch.clamp(P_BCa_2c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        if pytorch:\n",
    "                return -(LL_1c + LL_2c)\n",
    "        if df_length:\n",
    "                return len(V_B_w)\n",
    "        \n",
    "        if not pytorch and null_loglik:\n",
    "                n_1c = len(idx1)\n",
    "                n_2c = len(idx2)\n",
    "\n",
    "                if year>2016:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                else:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4 )).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).astype(float).values)\n",
    "\n",
    "                Choice_CC_1c, Choice_BB_1c, Choice_CaB_1c, Choice_BCa_1c = (\n",
    "                Choice_CC[idx1], Choice_BB[idx1], Choice_CaB[idx1], Choice_BCa[idx1])\n",
    "                Choice_CC_2c, Choice_BB_2c, Choice_CaB_2c, Choice_BCa_2c = (\n",
    "                Choice_CC[idx2], Choice_BB[idx2], Choice_CaB[idx2], Choice_BCa[idx2])\n",
    "\n",
    "                # observed shares\n",
    "                share_CC_1c = torch.sum(Choice_CC_1c) / n_1c\n",
    "                share_BB_1c = torch.sum(Choice_BB_1c) / n_1c\n",
    "                share_CaB_1c = torch.sum(Choice_CaB_1c) / n_1c\n",
    "                share_BCa_1c = torch.sum(Choice_BCa_1c) / n_1c\n",
    "\n",
    "                share_CC_2c = torch.sum(Choice_CC_2c) / n_2c\n",
    "                share_BB_2c = torch.sum(Choice_BB_2c) / n_2c\n",
    "                share_CaB_2c = torch.sum(Choice_CaB_2c) / n_2c\n",
    "                share_BCa_2c = torch.sum(Choice_BCa_2c) / n_2c\n",
    "\n",
    "                w_1c = var('WEIGHT_hh')\n",
    "                w_1c = w_1c[idx1]\n",
    "                w_2c = var('WEIGHT_hh')\n",
    "                w_2c = w_2c[idx2]\n",
    "\n",
    "                null_LL_1c = (\n",
    "                torch.sum(w_1c * Choice_CC_1c * torch.log(torch.clamp(share_CC_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BB_1c * torch.log(torch.clamp(share_BB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_CaB_1c * torch.log(torch.clamp(share_CaB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BCa_1c * torch.log(torch.clamp(share_BCa_1c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                null_LL_2c = (\n",
    "                torch.sum(w_2c * Choice_CC_2c * torch.log(torch.clamp(share_CC_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BB_2c * torch.log(torch.clamp(share_BB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_CaB_2c * torch.log(torch.clamp(share_CaB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BCa_2c * torch.log(torch.clamp(share_BCa_2c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                return -(null_LL_1c + null_LL_2c)\n",
    "        \n",
    "        if pareto_weight:\n",
    "                return Lambda\n",
    "        \n",
    "        if logsum:\n",
    "                LS_1c = sigma_1c_l1 * torch.log(\n",
    "                        torch.exp(V_BB/sigma_1c_l1) + torch.exp(V_CaB/sigma_1c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_1c_l1) + torch.exp(V_CpCd/sigma_1c_l1) + torch.exp(V_CdCp/sigma_1c_l1)\n",
    "                )\n",
    "                LS_2c = sigma_2c_l1 * torch.log(\n",
    "                        torch.exp(V_CaCa/sigma_2c_l1) + torch.exp(V_BB/sigma_2c_l1) + torch.exp(V_CaB/sigma_2c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_2c_l1) + torch.exp(V_CpCd/sigma_2c_l1) + torch.exp(V_CdCp/sigma_2c_l1)\n",
    "                )\n",
    "                return (LS_1c).detach().numpy(), (LS_2c).detach().numpy()\n",
    "        if utility_nestB:\n",
    "                return V_BB.detach().numpy()\n",
    "        \n",
    "        return -(LL_1c + LL_2c).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level1, parameters_level1 = Optimize(level1, \n",
    "         prepare_data_level1(df), \n",
    "        #  initial_values='Level1_CONSTRAINT',\n",
    "         max_iter=5000,\n",
    "         gtol=1,\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level1,\n",
    "               parameters_level1,\n",
    "               excel=True,\n",
    "               data=prepare_data_level1(df),\n",
    "               file_name='Level1_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0df9db",
   "metadata": {},
   "source": [
    "# Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['LS_1c'], df['LS_2c'] = level1(loaded_parameters, prepare_data_level1(df), logsum=True)\n",
    "\n",
    "def level2(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  logsum=False,\n",
    "                  all_sample=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx = df[\"at_least_one_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l2,\n",
    "        \n",
    "        ASC_2c_l2) = params\n",
    "\n",
    "        XB_2c = (torch.tensor(0))\n",
    "        \n",
    "        V_1car = var('LS_1c') \n",
    "        V_2car = (ASC_2c_l2 + XB_2c + var('LS_2c')) \n",
    "\n",
    "        # -------- Probabilities\n",
    "        V_stack = torch.stack([\n",
    "                V_1car[idx] / sigma_l2,\n",
    "                V_2car[idx] / sigma_l2\n",
    "        ], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_1car, P_2car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_1CAR = torch.tensor((choice['VOIT'] == 1).astype(int), dtype=torch.float64)\n",
    "        CHOICE_2CAR = torch.tensor((choice['VOIT'] >= 2).astype(int), dtype=torch.float64)\n",
    "\n",
    "        w = var('WEIGHT_hh')\n",
    "        w = w[idx]\n",
    "\n",
    "        epsilon=1e-30\n",
    "        LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.clamp(P_1car, min=epsilon))) +\n",
    "          torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.clamp(P_2car, min=epsilon))))\n",
    "        \n",
    "        if pytorch:\n",
    "                return -LL\n",
    "        \n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.sum(CHOICE_1CAR[idx])/len(idx)))\n",
    "                        + torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.sum(CHOICE_2CAR[idx])/len(idx))))\n",
    "                return -null_LL\n",
    "        \n",
    "        if df_length:\n",
    "                return len(idx)\n",
    "        \n",
    "        if logsum:\n",
    "                LS_level2 = sigma_l2 * torch.log(\n",
    "                        torch.exp(V_1car/sigma_l2) + torch.exp(V_2car/sigma_l2)\n",
    "                )\n",
    "                return (LS_level2).detach().numpy()\n",
    "        \n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level2, parameters_level2 = Optimize(level2, \n",
    "        prepare_data_level2(df), \n",
    "        #  initial_values='Level2_CONSTRAINT',\n",
    "        max_iter=5000,\n",
    "        gtol=1,\n",
    "        display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level2,\n",
    "               parameters_level2,\n",
    "               excel=True,\n",
    "               data=prepare_data_level2(df),\n",
    "               file_name='Level2_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8aa5c8",
   "metadata": {},
   "source": [
    "# Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15251f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level2, \n",
    "                file_name='Level2_UNCONSTRAINT')\n",
    "\n",
    "df['LS_car'] = level2(loaded_parameters, prepare_data_level2(df), logsum=True)\n",
    "\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['V_BB'] = level1(loaded_parameters, prepare_data_level1(df), utility_nestB=True)\n",
    "\n",
    "def level3(params, \n",
    "                df, \n",
    "                pytorch=False, \n",
    "                grad=False, \n",
    "                null_loglik=False, \n",
    "                df_length=False,\n",
    "                logsum=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l3,\n",
    "\n",
    "        ASC_car_l3) = params\n",
    "\n",
    "        XB_car = (torch.tensor(0))\n",
    "\n",
    "        V_NoCar = var('V_BB') \n",
    "        V_Car = ASC_car_l3 + XB_car + var('LS_car')\n",
    "\n",
    "        V_stack = torch.stack([\n",
    "                V_NoCar/sigma_l3, \n",
    "                V_Car/sigma_l3], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_NoCar, P_Car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_NOCAR = torch.tensor((choice['VOIT'] == 0).astype(int), dtype=torch.float64)\n",
    "        CHOICE_CAR = torch.tensor((choice['VOIT'] >= 1).astype(int), dtype=torch.float64)\n",
    "\n",
    "        epsilon=1e-30\n",
    "        w = var('WEIGHT_hh')\n",
    "\n",
    "        LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.clamp(P_NoCar, min=epsilon))) +\n",
    "                torch.sum(w * CHOICE_CAR * torch.log(torch.clamp(P_Car, min=epsilon))))\n",
    "\n",
    "        if pytorch:\n",
    "                return -LL\n",
    "\n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.sum(CHOICE_NOCAR)/len(CHOICE_NOCAR)))\n",
    "                        + torch.sum(w * CHOICE_CAR * torch.log(torch.sum(CHOICE_CAR)/len(CHOICE_CAR))))\n",
    "                return -null_LL\n",
    "\n",
    "        if df_length:\n",
    "                return len(df['df'])\n",
    "\n",
    "        if logsum:\n",
    "                LS_level3 = sigma_l3 * torch.log(\n",
    "                torch.exp(V_NoCar/sigma_l3) + torch.exp(V_Car/sigma_l3)\n",
    "                )\n",
    "                return (LS_level3).detach().numpy()\n",
    "\n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff53e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level3, parameters_level3 = Optimize(level3, \n",
    "         prepare_data_level3(df), \n",
    "        #  initial_values='Level3_CONSTRAINT',\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level3,\n",
    "               parameters_level3,\n",
    "               excel=True,\n",
    "               data=prepare_data_level3(df),\n",
    "               file_name='Level3_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0db95",
   "metadata": {},
   "source": [
    "# Simultaneous estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimultaneousNestLogitModel(params_all, df, null_loglik=False, pytorch=False, grad=False):\n",
    "\n",
    "    # here we need the lenght of the parameters of each level (except the last one)\n",
    "    p0 = len(LoadParameters(level0, 'Level0_UNCONSTRAINT'))\n",
    "    p1 = len(LoadParameters(level1, 'Level1_UNCONSTRAINT'))\n",
    "    p2 = len(LoadParameters(level2, 'Level2_UNCONSTRAINT'))\n",
    "\n",
    "    params0 = params_all[:p0]\n",
    "    params1 = params_all[p0:p0+p1]\n",
    "    params2 = params_all[p0+p1:p0+p1+p2]\n",
    "    params3 = params_all[p0+p1+p2:]\n",
    "\n",
    "    df0 = prepare_data_level0(df)\n",
    "    LS_m, LS_w = level0(params0, df0, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_m'] = LS_m\n",
    "    df['LS_w'] = LS_w\n",
    "\n",
    "    df1 = prepare_data_level1(df)\n",
    "    LS_1c, LS_2c = level1(params1, df1, logsum=True, all_sample=True)\n",
    "    V_BB = level1(params1, df1, utility_nestB=True, all_sample=True)\n",
    "\n",
    "    df['LS_1c'] = LS_1c\n",
    "    df['LS_2c'] = LS_2c\n",
    "\n",
    "    df2 = prepare_data_level2(df)\n",
    "    LS_car = level2(params2, df2, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_car'] = LS_car\n",
    "    df['V_BB'] = V_BB\n",
    "\n",
    "    df3 = prepare_data_level3(df)\n",
    "\n",
    "    LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL3 = level3(params3, df3, pytorch=True, grad=grad)\n",
    "\n",
    "    total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    if null_loglik:\n",
    "        LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL3 = level3(params3, df3, pytorch=True, grad=grad, null_loglik=True)\n",
    "\n",
    "        total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    return total_LL if pytorch else total_LL.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcc579",
   "metadata": {},
   "source": [
    "### Mandatory :\n",
    "\n",
    "- You have to start the simultaneous estimation by using the parameters that you estimated independently on each level \n",
    "- This model is highly non-linear, which means that if you start by random values, it will almost never converge and will stay stuck in a local optima \n",
    "- Also, starting with those *independetly estimated parameters* will save you a lot of time in terms of computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12676793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from independent estimated parameters\n",
    "all_params = torch.cat([\n",
    "    LoadParameters(level0, 'Level0_UNCONSTRAINT'),\n",
    "    LoadParameters(level1, 'Level1_UNCONSTRAINT'),\n",
    "    LoadParameters(level2, 'Level2_UNCONSTRAINT'),\n",
    "    LoadParameters(level3, 'Level3_UNCONSTRAINT')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to start from your simultaneously estimated parameters \n",
    "# But they have to be estimated first, and then saved \n",
    "joint_parameters = JointLoadParameters(\n",
    "    file_name='Joint_UNCONSTRAINT',\n",
    "    level0=level0,\n",
    "    level1=level1,\n",
    "    level2=level2,\n",
    "    level3=level3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = JointOptimize(\n",
    "    func=SimultaneousNestLogitModel, \n",
    "    data=df, \n",
    "    initial_values=all_params, # start from independent estimated parameters\n",
    "    gtol=1,\n",
    "    max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute the summary table (can take some time because the model is big)\n",
    "# between 1 and 2min usually\n",
    "table = JointDisplayResults(\n",
    "               func=SimultaneousNestLogitModel,\n",
    "               params=parameters,\n",
    "               data=df,\n",
    "               level0=level0,\n",
    "               level1=level1,\n",
    "               level2=level2,\n",
    "               level3=level3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JointSaveParameters(params=parameters,\n",
    "                    level0=level0,\n",
    "                    level1=level1,\n",
    "                    level2=level2,\n",
    "                    level3=level3,\n",
    "                    table=table,\n",
    "                    excel=True,\n",
    "                    file_name='Joint_UNCONSTRAINT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
