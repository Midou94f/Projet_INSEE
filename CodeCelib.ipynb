{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b378c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x).rstrip('0').rstrip('.') if x != 0 else '0')\n",
    "import numpy as np \n",
    "np.set_printoptions(suppress=True, precision=6)\n",
    "import polars as pl \n",
    "pl.Config(set_fmt_float=\"full\")\n",
    "pl.Config(tbl_cols=1000)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os \n",
    "import seaborn as sns\n",
    "np.random.seed(22)\n",
    "import torch \n",
    "\n",
    "# Modification ici pour importer les nouvelles fonctions adaptées aux célibataires\n",
    "from packages.utils2 import Optimize, JointOptimize\n",
    "from packages.utils2 import SaveParameters, LoadParameters, JointDisplayResults, JointSaveParameters, JointLoadParameters\n",
    "# Remplacer par les nouvelles fonctions pour les célibataires\n",
    "from packages.utils2 import prepare_data_level0_single, prepare_data_level1_single, prepare_data_level2_single\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9084478",
   "metadata": {},
   "source": [
    "# CODE MODEL - CELIBATAIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a790c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Année d'étude\n",
    "year = 2017\n",
    "\n",
    "# Charger les données\n",
    "data = pl.read_parquet(f'/Users/mehdifehri/Desktop/Conduite de Projet/Data/single_clean.parquet')\n",
    "\n",
    "# Supprimer les observations intrazonales\n",
    "data = data.filter(pl.col('INTRAZONAL') == 0)\n",
    "\n",
    "# Créer les poids normalisés pour tous les célibataires\n",
    "data = data.with_columns([\n",
    "    # Poids individuel normalisé\n",
    "    (pl.col('IPONDI') * (len(data) / pl.col('IPONDI').sum())).alias(\"WEIGHT\")\n",
    "])\n",
    "\n",
    "# Convertir en DataFrame pandas\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bebcb8",
   "metadata": {},
   "source": [
    "# Overall guidelines:\n",
    "\n",
    "- All parameters have to finish their names by _l* with * being the number of the level \\\n",
    "*For example : B_RES_INNERRING_l3 is the parameter of the \"couronne\" of the residential location in level 3*\n",
    "\n",
    "## Steps of estimation :\n",
    "\n",
    "1) Run the constraint model (without explanatory variables) \n",
    "2) Save the parameters of the constraint model, add some heterogeneity to the model \n",
    "3) Estimate again but with the parameters of the constraint model as initial values \n",
    "4) Save the parameters of the UNconstraint model (the one with heterogeneity)\n",
    "5) Add some new variables, estimate with the UNconstraint parameters as initial values\n",
    "6) Do it again until you are satified by your model \n",
    "\n",
    "## Tips :\n",
    "\n",
    "- To access a variable you have to use *var('my_variable')*, with **'my_variable'** being the name of the variable in your dataset \n",
    "- To add a variable with his associated parameter, you can name the parameter as you want (**by always adding the level at the end**) \\\n",
    "*For example : B_DIST_BIKE2_w_l0*var('DISTANCE')**2 \n",
    "- Note that we truncate the DISTANCE, TRAVEL TIME for WALK, BIKE and TC for a purpose of generalization when \\\n",
    "forcasting on different datasets where people could give extreme non-coherent values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc408e",
   "metadata": {},
   "source": [
    "# Level 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c201cbc",
   "metadata": {},
   "source": [
    "### Level 0 guidelines:\n",
    "\n",
    "- **!! IMPORTANT !!** :All parameters have to finish their names with _(gender)_l1 : **\"m\" for man and \"w\" for woman** \\\n",
    "*For example : B_WP_OUTERRING_m_l0 is the parameter of the \"couronne\" of the job location in level 1 for the man, B_WP_OUTERRING_w_l0 for woman*\n",
    "- Except for *sigma_l0* which is the same for the man and the woman\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- To add characteristics in the constant of a mode, you can add them in *XB* \\\n",
    "*For example : adding characteristics into XB_TC_m, is adding heterogeneity in the constant of the mode TC for the man*\n",
    "- To add characteristics in the VOT (value of time) of a mode, you can add them in the *torch.exp(delta_TT_MOTO_m_l0)* term \\\n",
    "For example :\n",
    "```python\n",
    "torch.exp(delta_TT_MOTO_m_l0 + VOT_OCCP_SELFEMPLOYED_MOTO_m_l0 * var('OCCP_SELFEMPLOYED_m')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18535866",
   "metadata": {},
   "source": [
    "### Level 0 function if your year of study is after 2016 (not included)\n",
    "\n",
    "- There is two different function for level 0 depending on the year of study : \\\n",
    "it is only after 2017 that INSEE has splitted MOTO and BIKE from the TWO WHEELS alternative. \\\n",
    "- So from 2017 there are 4 choices at the level 0 (BIKE, MOTO, TC and WALK), and before that \\\n",
    "there are 3 choices (TC, WALK and TWO WHEELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c2a3d2",
   "metadata": {},
   "source": [
    "# Spécificité de l'échantillon étudié : les célibataires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236dd62",
   "metadata": {},
   "source": [
    "Pour les célibataires, nous n'avons plus besoin du niveau 3 du modèle pour plusieurs raisons :\n",
    "\n",
    "Structure simplifiée : Dans le modèle complet pour les couples bi-actifs, le niveau 3 représente le choix d'achat de la première voiture spécifiquement pour les couples bi-actifs. C'est une décision distincte de l'achat d'une deuxième voiture.\n",
    "Décision unique pour les célibataires : Pour un célibataire, il n'y a qu'une seule décision d'achat de voiture à modéliser - posséder ou non une voiture. Il n'y a pas de distinction entre \"première\" et \"deuxième\" voiture comme pour les couples.\n",
    "Modèle à 3 niveaux pour les célibataires :\n",
    "\n",
    "Niveau 0 : Choix du mode de transport (marche, vélo, moto, transports en commun)\n",
    "Niveau 1 : Choix entre voiture et autres modes quand on a une voiture\n",
    "Niveau 2 : Décision d'achat d'une voiture (oui/non)\n",
    "\n",
    "\n",
    "\n",
    "En contraste, le modèle pour les couples bi-actifs a 4 niveaux car il doit gérer des choix conjoints plus complexes et la possibilité d'avoir 0, 1 ou 2+ voitures.\n",
    "Cette simplification est logique et reflète bien la réalité des célibataires, qui font face à des décisions moins complexes en matière de possession et d'utilisation de voiture par rapport aux couples, où les choix doivent être coordonnés entre deux personnes.RéessayerClaude peut faire des erreurs. Assurez-vous de vérifier ses réponses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c47012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_C(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les célibataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,  \n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # ----------- Fonctions d'utilité (une seule série pour tous les célibataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 \n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 \n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 \n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilités (une seule série pour tous les célibataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule série pour tous les célibataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule série pour tous les célibataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22634ee",
   "metadata": {},
   "source": [
    "## Principaux changements effectués:\n",
    "\n",
    "- Renommé la fonction en level0_single (au lieu de level0_singles)\n",
    "- Remplacé les indices séparés pour hommes/femmes par un seul indice level0_idx\n",
    "- Supprimé les suffixes _m et _w des paramètres\n",
    "- Ajouté des paramètres pour l'effet du genre (B_GENDER_*)\n",
    "- Créé une variable indicatrice GENDER_DUMMY basée sur SEXE\n",
    "- Unifié toutes les fonctions d'utilité, probabilités et calculs de log-likelihood\n",
    "- Dans logsum, retourne une seule série au lieu de deux (LS_m, LS_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb20bd",
   "metadata": {},
   "source": [
    "### Tips:\n",
    "- The function will stop optimizing after 5000 iterations, you modify it as you wish \n",
    "- You can modify the **gtol** parameter to get more precision on the estimation but \\\n",
    "it will be costly in terms of computation time\n",
    "- If your estimation takes too much time I suggest you to increase the **gtol** by 0.5 \n",
    "\n",
    "### How to estimate :\n",
    "\n",
    "- Run the first estimation by leaving the **initial_values** commented \n",
    "- Then you can see the estimated parameters in the **summary_level0** table \n",
    "- Save the parameters with the **SaveParameters** function => parameters will be saved in the parameters folder that is on the same folder as your code\n",
    "- Then you can add some new variables to your objective function, and start a new estimation with the last parameters as **initial_values**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85789a29",
   "metadata": {},
   "source": [
    "# Estimation des paramètres contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ca60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  44%|████▍     | 657/1500 [12:00<11:45,  1.20it/s, Objective Value=50290.19500]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  44%|████▍     | 657/1500 [12:04<15:29,  1.10s/it, Objective Value=50290.19500]\n"
     ]
    }
   ],
   "source": [
    "summary_level0, parameters_level0 = Optimize(\n",
    "    level0_single_C, \n",
    "    prepare_data_level0_single(df, year=2017), \n",
    "    max_iter=1500,\n",
    "    gtol=1,\n",
    "    display_results=True\n",
    ")\n",
    "\n",
    "# Sauvegarde des paramètres\n",
    "SaveParameters(\n",
    "    level0_single_C,\n",
    "    parameters_level0,  # Là c'est bien le tensor\n",
    "    excel=False,\n",
    "    data=prepare_data_level0_single(df, year=2017),\n",
    "    file_name='Level0_CONSTRAINT'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899f1ef5",
   "metadata": {},
   "source": [
    "#  Analyse et interprétation du modèle contraint – Choix modal des célibataires\n",
    "\n",
    "##  Vue d'ensemble\n",
    "\n",
    "Le modèle estimé est un modèle de choix discret (logit multinomial) pour les décisions de transport des **célibataires**, avec quatre alternatives :\n",
    "- **TC** (Transports en commun),\n",
    "- **Marche**,\n",
    "- **Moto**,\n",
    "- **Vélo**.\n",
    "\n",
    " **Attention : le modèle n’a pas convergé**. Cela signifie que l’optimisation n’a pas atteint un vrai minimum. Les résultats peuvent être interprétés avec **prudence**.\n",
    "\n",
    "---\n",
    "\n",
    "##  Interprétation des paramètres clés\n",
    "\n",
    "###  Paramètre d’échelle\n",
    "\n",
    "- `sigma_l0 = 6.46`  \n",
    "→ Valeur élevée ⇒ **forte hétérogénéité non observée** dans les comportements de choix.  \n",
    "→ Le modèle ne capte pas encore bien les différences individuelles (âge, genre, revenu…).\n",
    "\n",
    "---\n",
    "\n",
    "### Constantes modales (ASC)\n",
    "\n",
    "| Coefficient        | Interprétation |\n",
    "|--------------------|----------------|\n",
    "| `ASC_TC_l0 = 1.88`  | Préférence intrinsèque **positive** pour le TC (vs. marche). |\n",
    "| `ASC_BIKE_l0 = -4.20` | Aversion significative pour le vélo. |\n",
    "| `ASC_MOTO_l0 = -14.25` | Très forte aversion pour la moto. |\n",
    "\n",
    "➡️ Ces ASC mesurent la préférence **structurelle**, toutes choses égales par ailleurs, pour chaque mode par rapport à la référence (ici, **marche**).\n",
    "\n",
    "---\n",
    "\n",
    "### Sensibilité au temps de trajet\n",
    "\n",
    "| Coefficient               | Interprétation |\n",
    "|---------------------------|----------------|\n",
    "| `delta_TT_TC_l0 = -3.84`  | TC : l’utilité diminue avec le temps, mais à un **taux décroissant** (transformation exponentielle). |\n",
    "| `delta_TT_MOTO_l0 = 2.91` | **Contre-intuitif** : indiquerait une préférence pour des trajets moto plus longs. Peut signaler : erreur, multicolinéarité, ou biais d’identification. |\n",
    "| `B_TT_TC2_l0 = -2.86`     | TC : effet quadratique négatif ⇒ l’utilité **baisse plus vite** avec le temps. |\n",
    "| `B_TT_MOTO2_l0 = -0.77`   | Moto : idem, effet négatif en cas de long trajet. |\n",
    "\n",
    "---\n",
    "\n",
    "### Sensibilité à la distance\n",
    "\n",
    "| Coefficient                   | Interprétation |\n",
    "|-------------------------------|----------------|\n",
    "| `delta_DIST_BIKE_l0 = 1.17`   | **Contre-intuitif** : utilité augmente avec la distance à vélo. Peut indiquer que seuls les cyclistes endurants restent. |\n",
    "| `B_DIST_BIKE2_l0 = 0.07`      | Effet quadratique **faiblement positif**. |\n",
    "| `B_DIST_WALK2_l0 = -0.06`     | L’utilité de la marche diminue rapidement avec la distance (effet attendu). |\n",
    "\n",
    "---\n",
    "\n",
    "## Limites et réserves\n",
    "\n",
    "1. **Pas de convergence**  \n",
    "   ⇒ Interprétation des coefficients à faire **avec prudence**.\n",
    "\n",
    "2. **Paramètres contre-intuitifs**  \n",
    "   - `delta_TT_MOTO_l0` et `delta_DIST_BIKE_l0` ont des **signes inattendus**.\n",
    "   - Possibles causes :\n",
    "     - Variables importantes manquantes,\n",
    "     - Multicolinéarité,\n",
    "     - Mauvais point de départ.\n",
    "\n",
    "3. **Hétérogénéité non observée importante**  \n",
    "   - `sigma_l0` élevé = **beaucoup de variations** dans les comportements, **pas encore expliquées** par les variables actuelles.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Recommandations\n",
    "\n",
    "1. **Augmenter `max_iter`**  \n",
    "   Pour forcer l’optimisation à aller plus loin et espérer la convergence.\n",
    "\n",
    "2. **Enrichir le modèle**\n",
    "   Ajouter :\n",
    "   - Variables socio-démographiques (`AGED`, `SEXE`, `SANI`, `SURF`, etc.),\n",
    "   - Conditions de mobilité (`VOIT`, `GARL`, etc.),\n",
    "   - Statut (`ETUD`, `OCCP_*`, etc.).\n",
    "\n",
    "3. **Revoir la spécification fonctionnelle**  \n",
    "   Tester différentes transformations (log, racine, linéaire) pour :\n",
    "   - `DISTANCE`,\n",
    "   - `TT`,\n",
    "   - etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Pourquoi partir du modèle contraint ?\n",
    "\n",
    "Utiliser les paramètres estimés **contraints** comme point de départ du modèle enrichi est **la bonne pratique** :\n",
    "\n",
    "| Avantage | Détail |\n",
    "|----------|--------|\n",
    "| 🔁 Stabilité | L’optimisation démarre d’un **point économiquement réaliste**. |\n",
    "| ⏱️ Gain de temps | Moins d’itérations nécessaires. |\n",
    "| 📊 Comparabilité | Chaque version enrichie reste **cohérente avec la base**, facilitant l’analyse des écarts. |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 Conclusion\n",
    "\n",
    "Ce modèle contraint constitue une **base solide**. Bien qu’imparfait, il révèle déjà certaines tendances et ouvre la voie à une **modélisation plus fine** de la mobilité des célibataires par l’ajout d’hétérogénéité observée.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ace2c",
   "metadata": {},
   "source": [
    "# Estimation des paramètres non-contraints (modèle enrichit d'hétérogénéité)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb9e1d",
   "metadata": {},
   "source": [
    "## Stratégie d’enrichissement du modèle non contraint – Niveau 0 (Célibataires)\n",
    "\n",
    "### Objectif\n",
    "Obtenir un modèle nested logit **convergent**, **interprétable économiquement**, et **statistiquement robuste**, en partant d’une spécification simple puis en ajoutant progressivement des variables explicatives issues du fichier `single_clean.parquet`.\n",
    "\n",
    "---\n",
    "\n",
    "###  Étape 0 – Modèle contraint de base\n",
    "- **Variables intégrées** : `TT_TC`, `FREEFLOW_TT`, `DISTANCE`, constantes ASC par mode (`ASC_MOTO`, `ASC_BIKE`, `ASC_TC`), et effets quadratiques.\n",
    "- **Hypothèse** : comportement modal homogène, pas d’hétérogénéité interindividuelle.\n",
    "- **But** : obtenir une première estimation stable (Level0_CONSTRAINT).\n",
    "\n",
    "---\n",
    "\n",
    "### Étape 1 – Genre (`SEXE`)\n",
    "- **Justification** : les préférences modales peuvent varier selon le genre (ex. sécurité, effort physique, normes sociales).\n",
    "- **Implémentation** :\n",
    "  - Ajout de `GENDER_DUMMY = 1 si femme`,\n",
    "  - Paramètres `B_GENDER_TC`, `B_GENDER_MOTO`, `B_GENDER_BIKE`.\n",
    "\n",
    "---\n",
    "###  Étape 2 – Hétérogénéité par âge (`AGED`)\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- L’âge affecte les préférences modales : mobilité physique, tolérance au temps de trajet, préférence pour la marche ou la voiture.\n",
    "- C’est une variable continue structurante du comportement.\n",
    "\n",
    "#### ✅ Implémentation :\n",
    "- Ajouter `AGED` centré (ex : `(AGED - 40)/10`) et son carré dans les `XB_*` des utilités.\n",
    "\n",
    "---\n",
    "\n",
    "### 🪜 Étape 3 – Hétérogénéité socio-économique\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- Pour capturer les différences de ressources, d’accès aux modes, de contraintes et de préférences modales.\n",
    "\n",
    "####  Variables proposées :\n",
    "- `SANI` : équipement sanitaire (0 = très précaire → 2 = standard), **proxy de pauvreté matérielle**.\n",
    "- `SURF` : superficie du logement (en classes), **proxy de richesse immobilière**.\n",
    "- `HOMEOWNERSHIP` : statut d’occupation (1 = propriétaire, autres = locataire), **proxy de stabilité économique**.\n",
    "- `VOIT` : nombre de voitures dans le ménage, indicateur **d’accès à la voiture privée**.\n",
    "- `GARL` : place de stationnement disponible.\n",
    "\n",
    "---\n",
    "\n",
    "### 🪜 Étape 4 – Hétérogénéité démographique\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- Composition du ménage influence les contraintes et préférences :\n",
    "  - enfants → contraintes horaires,\n",
    "  - grande taille → préférence pour modes confortables.\n",
    "\n",
    "####  Variables proposées :\n",
    "- `NENFR` : nombre d’enfants dans le ménage,\n",
    "- `NPERR` : nombre total de personnes dans le ménage.\n",
    "\n",
    "---\n",
    "\n",
    "### 🪜 Étape 5 – Étudiants (`ETUD`)\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- Les étudiants ont des contraintes et préférences spécifiques :\n",
    "  - Moins d’accès à la voiture,\n",
    "  - Préférence pour TC ou marche,\n",
    "  - Moindre valeur du temps.\n",
    "\n",
    "####  Implémentation :\n",
    "- Créer une dummy `IS_STUDENT = 1` si `ETUD == 1`.\n",
    "\n",
    "---\n",
    "\n",
    "### 🪜 Étape 6 – Occupation professionnelle (`OCCP_*`)\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- Statut professionnel structurant :\n",
    "  - `OCCP_EMPLOYEE` / `OCCP_BLUE_COLLAR` → effets de distance et coût,\n",
    "  - `OCCP_SELF_EMPLOYED` → flexibilité horaire,\n",
    "  - `OCCP_WHITE_COLLAR`, `OCCP_PROFESSIONAL` → accessibilité modale différente.\n",
    "\n",
    "####  Implémentation :\n",
    "- Ajouter des effets spécifiques dans les `XB_*` selon la catégorie dominante.\n",
    "\n",
    "---\n",
    "\n",
    "### 🪜 Étape 7 – Effet spatial (zones géographiques)\n",
    "\n",
    "#### 🔍 Justification :\n",
    "- Lieu de résidence et de travail = **fort déterminant structurel** du comportement modal.\n",
    "\n",
    "####  Variables proposées :\n",
    "- Résidence : `RES_PARIS`, `RES_INNERRING`, `RES_OUTERRING`,\n",
    "- Travail : `WP_PARIS`, `WP_INNERRING`, `WP_OUTERRING`.\n",
    "\n",
    "---\n",
    "\n",
    "### Méthodologie à chaque étape :\n",
    "\n",
    "1. Ajouter les variables dans les `XB_*` de la fonction `level0_single_NC`,\n",
    "2. Ajouter les coefficients correspondants dans `params = (...)`,\n",
    "3. Relancer l’estimation avec `initial_values='Level0_CONSTRAINT'`,\n",
    "4. Sauvegarder les résultats sous `\"Level0_UNCONSTRAINT_ETAPE_X\"`,\n",
    "5. Vérifier :\n",
    "   - Convergence,\n",
    "   - Signifiance des coefficients,\n",
    "   - Interprétabilité économique.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Objectif final :\n",
    "Un modèle :\n",
    "- convergent (log-likelihood stable),\n",
    "- économiquement cohérent,\n",
    "- interprétable (signes attendus),\n",
    "- utilisable pour prédiction ou comparaison avec les couples monoactifs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831968e8",
   "metadata": {},
   "source": [
    "# Modèle non-contraint enrichit : Test avec 'GENRE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6ccc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_NC1(params, \n",
    "           df,\n",
    "           pytorch=False, \n",
    "           null_loglik=False, \n",
    "           grad=False, \n",
    "           logsum=False,\n",
    "           df_length=False,\n",
    "           all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les célibataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,  \n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0,\n",
    "    \n",
    "    B_GENDER_TC_l0,\n",
    "    B_GENDER_MOTO_l0,\n",
    "    B_GENDER_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # Indicatrice de genre: 1 si femme (SEXE=2), 0 si homme (SEXE=1)\n",
    "    GENDER_DUMMY = (var('SEXE') == 2).float()\n",
    "\n",
    "    # Constantes avec effet du genre\n",
    "    XB_TC = B_GENDER_TC_l0 * GENDER_DUMMY\n",
    "    XB_MOTO = B_GENDER_MOTO_l0 * GENDER_DUMMY\n",
    "    XB_BIKE = B_GENDER_BIKE_l0 * GENDER_DUMMY\n",
    "\n",
    "    # ----------- Fonctions d'utilité (une seule série pour tous les célibataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 + XB_TC\n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 + XB_MOTO\n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 + XB_BIKE\n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilités (une seule série pour tous les célibataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule série pour tous les célibataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule série pour tous les célibataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be908b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  29%|██▉       | 145/500 [01:33<03:48,  1.55it/s, Objective Value=47536.62786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/mehdifehri/Desktop/Conduite de Projet/Code/packages')\n",
    "\n",
    "from utils2 import Optimize, prepare_data_level0_single, SaveParameters\n",
    "\n",
    "# Version correcte avec display_results=False\n",
    "parameters_level0 = Optimize(level0_single_NC1, \n",
    "         prepare_data_level0_single(df, year=2017),\n",
    "         initial_values='Level0_CONSTRAINT',\n",
    "         max_iter=500,\n",
    "         gtol=1,\n",
    "         display_results=False)  # Quand c'est False, la fonction ne renvoie que les paramètres\n",
    "\n",
    "# Sauvegarde des paramètres\n",
    "SaveParameters(level0_single_NC1,\n",
    "              parameters_level0,\n",
    "              excel=False,  # False pour éviter l'erreur de la matrice hessienne\n",
    "              data=prepare_data_level0_single(df, year=2017),\n",
    "              file_name='Level0_NC1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a9b0a",
   "metadata": {},
   "source": [
    "Le model est convergent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72affe5",
   "metadata": {},
   "source": [
    "# Etape 2 : test variable 'Age + Age^2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96de2a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level0_single_NC2(params, \n",
    "                     df,\n",
    "                     pytorch=False, \n",
    "                     null_loglik=False, \n",
    "                     grad=False, \n",
    "                     logsum=False,\n",
    "                     df_length=False,\n",
    "                     all_sample=False):\n",
    "    \n",
    "    v = df['vars']\n",
    "\n",
    "    if all_sample:\n",
    "        idx = df['all_idx']\n",
    "    else:\n",
    "        idx = df['level0_idx']  # Un seul indice pour tous les célibataires\n",
    "\n",
    "    def var(name): return v[name]\n",
    "\n",
    "    if grad:\n",
    "        params = params.clone().requires_grad_(True)\n",
    "    else:\n",
    "        params = torch.tensor(params, dtype=torch.float64)\n",
    "        \n",
    "    (sigma_l0, \n",
    "    ASC_MOTO_l0, ASC_BIKE_l0, ASC_TC_l0,\n",
    "\n",
    "    B_DIST_BIKE2_l0, \n",
    "    B_DIST_WALK2_l0,\n",
    "    B_TT_TC2_l0,\n",
    "    B_TT_MOTO2_l0,\n",
    "    delta_TT_TC_l0,\n",
    "    delta_TT_MOTO_l0,\n",
    "    delta_DIST_BIKE_l0,\n",
    "    \n",
    "    B_GENDER_TC_l0,\n",
    "    B_GENDER_MOTO_l0,\n",
    "    B_GENDER_BIKE_l0,\n",
    "    \n",
    "    B_AGE_TC_l0,\n",
    "    B_AGE_MOTO_l0,\n",
    "    B_AGE_BIKE_l0,\n",
    "    \n",
    "    B_AGE2_TC_l0,\n",
    "    B_AGE2_MOTO_l0,\n",
    "    B_AGE2_BIKE_l0\n",
    "    ) = params\n",
    "\n",
    "    # Indicatrice de genre: 1 si femme (SEXE=2), 0 si homme (SEXE=1)\n",
    "    GENDER_DUMMY = (var('SEXE') == 2).float()\n",
    "    \n",
    "    # Variable d'âge (normalisée pour éviter les problèmes numériques)\n",
    "    AGE = var('AGED') - 40  # Centrer autour de 40 ans\n",
    "    AGE2 = AGE**2 / 100     # Mettre à l'échelle pour éviter des valeurs trop grandes\n",
    "\n",
    "    # Constantes avec effet du genre et de l'âge\n",
    "    XB_TC = (B_GENDER_TC_l0 * GENDER_DUMMY + \n",
    "             B_AGE_TC_l0 * AGE + \n",
    "             B_AGE2_TC_l0 * AGE2)\n",
    "    \n",
    "    XB_MOTO = (B_GENDER_MOTO_l0 * GENDER_DUMMY + \n",
    "               B_AGE_MOTO_l0 * AGE + \n",
    "               B_AGE2_MOTO_l0 * AGE2)\n",
    "    \n",
    "    XB_BIKE = (B_GENDER_BIKE_l0 * GENDER_DUMMY + \n",
    "               B_AGE_BIKE_l0 * AGE + \n",
    "               B_AGE2_BIKE_l0 * AGE2)\n",
    "\n",
    "    # ----------- Fonctions d'utilité (une seule série pour tous les célibataires)\n",
    "\n",
    "    V_TC = (ASC_TC_l0 + XB_TC\n",
    "            - torch.exp(delta_TT_TC_l0) * torch.min(var('TT_TC'), torch.tensor((180/60))) \n",
    "            + B_TT_TC2_l0 * (torch.min(var('TT_TC'), torch.tensor((180/60)))**2))\n",
    "    \n",
    "    V_WALK = (-3 * torch.min(var('DISTANCE'), torch.tensor(10)) \n",
    "              + B_DIST_WALK2_l0 * (torch.min(var('DISTANCE'), torch.tensor(10))**2) \n",
    "              ) \n",
    "\n",
    "    V_MOTO = (ASC_MOTO_l0 + XB_MOTO\n",
    "              - torch.exp(delta_TT_MOTO_l0) * var('FREEFLOW_TT') \n",
    "              + B_TT_MOTO2_l0 * (var('FREEFLOW_TT')**2)) \n",
    "        \n",
    "    V_BIKE = (ASC_BIKE_l0 + XB_BIKE\n",
    "              - torch.exp(delta_DIST_BIKE_l0) * torch.min(var('DISTANCE'), torch.tensor(25))\n",
    "              + B_DIST_BIKE2_l0 * (torch.min(var('DISTANCE'), torch.tensor(25))**2)\n",
    "              )\n",
    "    \n",
    "    # ------------- Probabilités (une seule série pour tous les célibataires)\n",
    "    \n",
    "    V_stack = torch.stack([V_TC[idx] / sigma_l0, \n",
    "                        V_MOTO[idx] / sigma_l0, \n",
    "                        V_WALK[idx] / sigma_l0, \n",
    "                        V_BIKE[idx] / sigma_l0], dim=1)\n",
    "    max_V = V_stack.max()\n",
    "    exp_V = torch.exp(V_stack - max_V)\n",
    "    sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "    P_TC, P_MOTO, P_WALK, P_BIKE = exp_V.T / sum_exp\n",
    "\n",
    "    # Choix de mode (une seule série pour tous les célibataires)\n",
    "    choices = df['df']\n",
    "    \n",
    "    Choice_TC = torch.tensor((choices['COMMUTE_MODE']=='PUBLIC').astype(int).values, dtype=torch.float64)\n",
    "    Choice_WALK = torch.tensor((choices['COMMUTE_MODE']=='WALK').astype(int).values, dtype=torch.float64)\n",
    "    Choice_MOTO = torch.tensor((choices['COMMUTE_MODE']=='MOTO').astype(int).values, dtype=torch.float64)\n",
    "    Choice_BIKE = torch.tensor((choices['COMMUTE_MODE']=='BIKE').astype(int).values, dtype=torch.float64)\n",
    "\n",
    "    weights = var('WEIGHT')\n",
    "    weights = weights[idx]\n",
    "    \n",
    "    if null_loglik:\n",
    "        null_LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.sum(Choice_TC[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.sum(Choice_MOTO[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_WALK[idx] * torch.log(torch.sum(Choice_WALK[idx])/len(idx))) + \\\n",
    "                torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.sum(Choice_BIKE[idx])/len(idx)))\n",
    "\n",
    "        return -null_LL\n",
    "\n",
    "    epsilon = 1e-30  \n",
    "\n",
    "    # Log-likelihood (une seule série pour tous les célibataires)\n",
    "    LL = torch.sum(weights * Choice_TC[idx] * torch.log(torch.clamp(P_TC, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_MOTO[idx] * torch.log(torch.clamp(P_MOTO, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_WALK[idx] * torch.log(torch.clamp(P_WALK, min=epsilon))) + \\\n",
    "        torch.sum(weights * Choice_BIKE[idx] * torch.log(torch.clamp(P_BIKE, min=epsilon)))\n",
    "\n",
    "    if pytorch:\n",
    "        return -LL\n",
    "        \n",
    "    if logsum:\n",
    "        LS = sigma_l0 * torch.log(\n",
    "            torch.exp(V_TC / sigma_l0) + torch.exp(V_MOTO / sigma_l0) \n",
    "            + torch.exp(V_WALK / sigma_l0) + torch.exp(V_BIKE / sigma_l0) \n",
    "        )\n",
    "        return LS\n",
    "    \n",
    "    if df_length:\n",
    "        return len(idx)\n",
    "        \n",
    "    return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f0b608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing:  37%|███▋      | 186/500 [02:14<03:46,  1.38it/s, Objective Value=47388.46652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence: True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/mehdifehri/Desktop/Conduite de Projet/Code/packages')\n",
    "\n",
    "from utils2 import Optimize, prepare_data_level0_single, SaveParameters\n",
    "\n",
    "# Version correcte avec display_results=False\n",
    "parameters_level0 = Optimize(level0_single_NC2, \n",
    "         prepare_data_level0_single(df, year=2017),\n",
    "         initial_values='Level0_NC1',\n",
    "         max_iter=500,\n",
    "         gtol=1,\n",
    "         display_results=False)  # Quand c'est False, la fonction ne renvoie que les paramètres\n",
    "\n",
    "# Sauvegarde des paramètres\n",
    "SaveParameters(level0_single_NC2,\n",
    "              parameters_level0,\n",
    "              excel=False,  # False pour éviter l'erreur de la matrice hessienne\n",
    "              data=prepare_data_level0_single(df, year=2017),\n",
    "              file_name='Level0_NC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e239a1f3",
   "metadata": {},
   "source": [
    "Il est généralement plus efficace d'utiliser les paramètres obtenus à l'étape précédente, c'est-à-dire ceux du modèle non contraint précédent (celui avec âge et genre).\n",
    "Il y a plusieurs raisons à cela:\n",
    "\n",
    "Continuité des paramètres: Les paramètres des variables déjà incluses (âge, genre) auront des valeurs proches de celles estimées précédemment, ce qui facilite la convergence.\n",
    "Stabilité numérique: Partir des estimations précédentes vous place déjà dans une région \"probable\" de l'espace des paramètres, réduisant les risques de divergence.\n",
    "Démarche progressive: Cela s'inscrit dans une logique d'enrichissement progressif où chaque modèle est une extension du précédent.\n",
    "\n",
    "Votre approche serait donc:\n",
    "\n",
    "Modèle contraint (base) → valeurs initiales pour modèle avec âge et genre\n",
    "Modèle avec âge et genre → valeurs initiales pour modèle avec âge, genre et variables socio-économiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a446a",
   "metadata": {},
   "source": [
    "# Etape 2 : test variables socio-économiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0aaf0f",
   "metadata": {},
   "source": [
    "# Level 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86115c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ecb895",
   "metadata": {},
   "source": [
    "## Parameter names convention :\n",
    "\n",
    "- for the parameters of the Pareto weight (Lambda) : begin with **L_**\n",
    "- for the parameters of the different constants : begin with **B_**\n",
    "- for the parameters of the value of time : begin with **votCA_** if the value of time of car alone, **votCP_** if car passenger, etc.\n",
    "- the end of each parameter should always follow the rules of each level : so, here each parameter ends with : **_l1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98b9c25",
   "metadata": {},
   "source": [
    "### Tips :\n",
    "- Here we start by computing the *logsum* resulting from level 0. Be careful to load the right parameters to compute it \\\n",
    "otherwise you will end up with a wrong *logsum* term \n",
    "- This level is the **hardest to identify** : I recommand you to add variables in the Lambda, \\\n",
    "the constants of OTHERS (being the case of choosing other modes than car), and the VOT of car alone at the same time \n",
    "- *ASC_Cp_m_l1*, *ASC_Cp_w_l1*, *ASC_Cd_m_l1*, *ASC_Cd_w_l1* and \\\n",
    "*delta_Cp_m_l1*, *delta_Cp_w_l1*, *delta_Cd_m_l1*, *delta_Cd_w_l1* are the **hardest to identify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the parameters of the final model in level 0 (so the last UNconstraint model that you've estimated)\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level0, \n",
    "                file_name='Level0_UNCONSTRAINT') \n",
    "\n",
    "# this adds the logsums of the man and the woman to the dataset\n",
    "df['LS_m'], df['LS_w'] = level0(loaded_parameters, prepare_data_level0(df, year=year), logsum=True)\n",
    "\n",
    "\n",
    "def level1(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  pareto_weight=False,\n",
    "                  logsum=False,\n",
    "                  utility_nestB=False,\n",
    "                  all_sample=False,\n",
    "                  year=year):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx1 = df[\"all_idx\"]\n",
    "                idx2 = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx1 = df[\"is_one_car_idx\"]\n",
    "                idx2 = df[\"is_multi_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "    \n",
    "        (\n",
    "        sigma_1c_l1, sigma_2c_l1,\n",
    "\n",
    "        ASC_Cp_m_l1, ASC_Cp_w_l1,\n",
    "        ASC_Cd_m_l1, ASC_Cd_w_l1,\n",
    "\n",
    "        ASC_B_w_l1, delta_Ca_w_l1, delta_Cd_w_l1, delta_Cp_w_l1,\n",
    "        ASC_B_m_l1, delta_Ca_m_l1, delta_Cp_m_l1, delta_Cd_m_l1,\n",
    "\n",
    "        ) = params\n",
    "\n",
    "        Xb_Lambda = (torch.tensor(0))\n",
    "\n",
    "        Lambda = 1 / (1 + torch.exp(-Xb_Lambda))\n",
    "\n",
    "        Xb_m_OTHERS = (torch.tensor(0))\n",
    "                       \n",
    "        Xb_w_OTHERS = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CP = (torch.tensor(0))\n",
    "\n",
    "        Xb_m_CD = (torch.tensor(0))\n",
    "\n",
    "        Xb_w_CD = (torch.tensor(0))\n",
    "\n",
    "        # individual vot and utilities:\n",
    "        VOT_Ca_m = torch.exp(delta_Ca_m_l1)\n",
    "        \n",
    "        VOT_Ca_w = torch.exp(delta_Ca_w_l1)\n",
    "\n",
    "        V_Ca_m = -VOT_Ca_m*var('TT_VP_m')\n",
    "        V_Ca_w = -VOT_Ca_w*var('TT_VP_w')\n",
    "\n",
    "        V_Cp_m = (ASC_Cp_m_l1 + Xb_m_CP) - VOT_Ca_m*torch.exp(delta_Cp_m_l1)*var('TT_VP_m') \n",
    "        V_Cp_w = (ASC_Cp_w_l1 + Xb_w_CP) - VOT_Ca_w*torch.exp(delta_Cp_w_l1)*var('TT_VP_w') \n",
    "\n",
    "        V_Cd_m = (ASC_Cd_m_l1 + Xb_m_CD) - VOT_Ca_m*torch.exp(delta_Cd_m_l1)*var('TT_VP_w') - VOT_Ca_m*var('WOMANtowardsMAN')\n",
    "        V_Cd_w = (ASC_Cd_w_l1 + Xb_w_CD) - VOT_Ca_w*torch.exp(delta_Cd_w_l1)*var('TT_VP_m') - VOT_Ca_w*var('MANtowardsWOMAN')\n",
    "\n",
    "        V_B_m = (ASC_B_m_l1 + Xb_m_OTHERS) + var('LS_m')\n",
    "        V_B_w = (ASC_B_w_l1 + Xb_w_OTHERS) + var('LS_w')\n",
    "\n",
    "        # Utilitaires collectifs : (extrait)\n",
    "        V_CaCa = Lambda * V_Ca_w + (1 - Lambda) * V_Ca_m\n",
    "        V_BB = Lambda * V_B_w + (1 - Lambda) * V_B_m\n",
    "        V_CaB = Lambda * V_Ca_w + (1 - Lambda) * V_B_m\n",
    "        V_BCa = Lambda * V_B_w + (1 - Lambda) * V_Ca_m\n",
    "        V_CdCp = Lambda * V_Cd_w + (1 - Lambda) * V_Cp_m\n",
    "        V_CpCd = Lambda * V_Cp_w + (1 - Lambda) * V_Cd_m\n",
    "\n",
    "        # -------- One-car probabilities\n",
    "        V_1c_stack = torch.stack([\n",
    "                V_BB[idx1] / sigma_1c_l1,\n",
    "                V_CaB[idx1] / sigma_1c_l1,\n",
    "                V_BCa[idx1] / sigma_1c_l1,\n",
    "                V_CdCp[idx1] / sigma_1c_l1,\n",
    "                V_CpCd[idx1] / sigma_1c_l1\n",
    "        ], dim=1)\n",
    "        max_V_1c = V_1c_stack.max()\n",
    "        exp_V_1c = torch.exp(V_1c_stack - max_V_1c)\n",
    "        sum_exp_1c = exp_V_1c.sum(dim=1)\n",
    "\n",
    "        P_BB_1c, P_CaB_1c, P_BCa_1c, P_CdCp_1c, P_CpCd_1c = exp_V_1c.T / sum_exp_1c\n",
    "\n",
    "        # -------- Two-car probabilities\n",
    "        V_2c_stack = torch.stack([\n",
    "                V_CaCa[idx2] / sigma_2c_l1,\n",
    "                V_BB[idx2] / sigma_2c_l1,\n",
    "                V_CaB[idx2] / sigma_2c_l1,\n",
    "                V_BCa[idx2] / sigma_2c_l1,\n",
    "                V_CdCp[idx2] / sigma_2c_l1,\n",
    "                V_CpCd[idx2] / sigma_2c_l1\n",
    "        ], dim=1)\n",
    "        max_V_2c = V_2c_stack.max()\n",
    "        exp_V_2c = torch.exp(V_2c_stack - max_V_2c)\n",
    "        sum_exp_2c = exp_V_2c.sum(dim=1)\n",
    "\n",
    "        P_CaCa_2c, P_BB_2c, P_CaB_2c, P_BCa_2c, P_CdCp_2c, P_CpCd_2c = exp_V_2c.T / sum_exp_2c\n",
    "\n",
    "        # -------- Choices\n",
    "        choices = df['df']\n",
    "\n",
    "        if year>2016:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).to_numpy().astype(float)\n",
    "        else:\n",
    "                Choice_CC = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "                Choice_BB = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_CaB = ((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).to_numpy().astype(float)\n",
    "                Choice_BCa = ((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).to_numpy().astype(float)\n",
    "\n",
    "\n",
    "        w_1c = var('WEIGHT_hh')\n",
    "        w_1c = w_1c[idx1]\n",
    "        w_2c = var('WEIGHT_hh')\n",
    "        w_2c = w_2c[idx2]\n",
    "\n",
    "        epsilon = 1e-30\n",
    "\n",
    "        LL_1c = (\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CC)[idx1] * torch.log(torch.clamp(P_CdCp_1c + P_CpCd_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BB)[idx1] * torch.log(torch.clamp(P_BB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_CaB)[idx1] * torch.log(torch.clamp(P_CaB_1c, min=epsilon))) +\n",
    "        torch.sum(w_1c * torch.tensor(Choice_BCa)[idx1] * torch.log(torch.clamp(P_BCa_1c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        LL_2c = (\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CC)[idx2] * torch.log(torch.clamp(P_CaCa_2c + P_CdCp_2c + P_CpCd_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BB)[idx2] * torch.log(torch.clamp(P_BB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_CaB)[idx2] * torch.log(torch.clamp(P_CaB_2c, min=epsilon))) +\n",
    "        torch.sum(w_2c * torch.tensor(Choice_BCa)[idx2] * torch.log(torch.clamp(P_BCa_2c, min=epsilon)))\n",
    "        )\n",
    "\n",
    "        if pytorch:\n",
    "                return -(LL_1c + LL_2c)\n",
    "        if df_length:\n",
    "                return len(V_B_w)\n",
    "        \n",
    "        if not pytorch and null_loglik:\n",
    "                n_1c = len(idx1)\n",
    "                n_2c = len(idx2)\n",
    "\n",
    "                if year>2016:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 5) & (choices['TRANS_m'].isin([2, 3, 4, 6]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 4, 6])) & (choices['TRANS_m'] == 5)).astype(float).values)\n",
    "                else:\n",
    "                        Choice_CC = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'] == 4 )).astype(float).values)\n",
    "                        Choice_BB = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_CaB = torch.tensor(((choices['TRANS_w'] == 4) & (choices['TRANS_m'].isin([2, 3, 5]))).astype(float).values)\n",
    "                        Choice_BCa = torch.tensor(((choices['TRANS_w'].isin([2, 3, 5])) & (choices['TRANS_m'] == 4)).astype(float).values)\n",
    "\n",
    "                Choice_CC_1c, Choice_BB_1c, Choice_CaB_1c, Choice_BCa_1c = (\n",
    "                Choice_CC[idx1], Choice_BB[idx1], Choice_CaB[idx1], Choice_BCa[idx1])\n",
    "                Choice_CC_2c, Choice_BB_2c, Choice_CaB_2c, Choice_BCa_2c = (\n",
    "                Choice_CC[idx2], Choice_BB[idx2], Choice_CaB[idx2], Choice_BCa[idx2])\n",
    "\n",
    "                # observed shares\n",
    "                share_CC_1c = torch.sum(Choice_CC_1c) / n_1c\n",
    "                share_BB_1c = torch.sum(Choice_BB_1c) / n_1c\n",
    "                share_CaB_1c = torch.sum(Choice_CaB_1c) / n_1c\n",
    "                share_BCa_1c = torch.sum(Choice_BCa_1c) / n_1c\n",
    "\n",
    "                share_CC_2c = torch.sum(Choice_CC_2c) / n_2c\n",
    "                share_BB_2c = torch.sum(Choice_BB_2c) / n_2c\n",
    "                share_CaB_2c = torch.sum(Choice_CaB_2c) / n_2c\n",
    "                share_BCa_2c = torch.sum(Choice_BCa_2c) / n_2c\n",
    "\n",
    "                w_1c = var('WEIGHT_hh')\n",
    "                w_1c = w_1c[idx1]\n",
    "                w_2c = var('WEIGHT_hh')\n",
    "                w_2c = w_2c[idx2]\n",
    "\n",
    "                null_LL_1c = (\n",
    "                torch.sum(w_1c * Choice_CC_1c * torch.log(torch.clamp(share_CC_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BB_1c * torch.log(torch.clamp(share_BB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_CaB_1c * torch.log(torch.clamp(share_CaB_1c, min=epsilon))) +\n",
    "                torch.sum(w_1c * Choice_BCa_1c * torch.log(torch.clamp(share_BCa_1c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                null_LL_2c = (\n",
    "                torch.sum(w_2c * Choice_CC_2c * torch.log(torch.clamp(share_CC_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BB_2c * torch.log(torch.clamp(share_BB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_CaB_2c * torch.log(torch.clamp(share_CaB_2c, min=epsilon))) +\n",
    "                torch.sum(w_2c * Choice_BCa_2c * torch.log(torch.clamp(share_BCa_2c, min=epsilon)))\n",
    "                )\n",
    "\n",
    "                return -(null_LL_1c + null_LL_2c)\n",
    "        \n",
    "        if pareto_weight:\n",
    "                return Lambda\n",
    "        \n",
    "        if logsum:\n",
    "                LS_1c = sigma_1c_l1 * torch.log(\n",
    "                        torch.exp(V_BB/sigma_1c_l1) + torch.exp(V_CaB/sigma_1c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_1c_l1) + torch.exp(V_CpCd/sigma_1c_l1) + torch.exp(V_CdCp/sigma_1c_l1)\n",
    "                )\n",
    "                LS_2c = sigma_2c_l1 * torch.log(\n",
    "                        torch.exp(V_CaCa/sigma_2c_l1) + torch.exp(V_BB/sigma_2c_l1) + torch.exp(V_CaB/sigma_2c_l1) \n",
    "                        + torch.exp(V_BCa/sigma_2c_l1) + torch.exp(V_CpCd/sigma_2c_l1) + torch.exp(V_CdCp/sigma_2c_l1)\n",
    "                )\n",
    "                return (LS_1c).detach().numpy(), (LS_2c).detach().numpy()\n",
    "        if utility_nestB:\n",
    "                return V_BB.detach().numpy()\n",
    "        \n",
    "        return -(LL_1c + LL_2c).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level1, parameters_level1 = Optimize(level1, \n",
    "         prepare_data_level1(df), \n",
    "        #  initial_values='Level1_CONSTRAINT',\n",
    "         max_iter=5000,\n",
    "         gtol=1,\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level1,\n",
    "               parameters_level1,\n",
    "               excel=True,\n",
    "               data=prepare_data_level1(df),\n",
    "               file_name='Level1_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0df9db",
   "metadata": {},
   "source": [
    "# Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['LS_1c'], df['LS_2c'] = level1(loaded_parameters, prepare_data_level1(df), logsum=True)\n",
    "\n",
    "def level2(params, \n",
    "                  df, \n",
    "                  pytorch=False, \n",
    "                  grad=False, \n",
    "                  null_loglik=False, \n",
    "                  df_length=False,\n",
    "                  logsum=False,\n",
    "                  all_sample=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        if all_sample:\n",
    "                idx = df[\"all_idx\"]\n",
    "        else:\n",
    "                idx = df[\"at_least_one_car_idx\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l2,\n",
    "        \n",
    "        ASC_2c_l2) = params\n",
    "\n",
    "        XB_2c = (torch.tensor(0))\n",
    "        \n",
    "        V_1car = var('LS_1c') \n",
    "        V_2car = (ASC_2c_l2 + XB_2c + var('LS_2c')) \n",
    "\n",
    "        # -------- Probabilities\n",
    "        V_stack = torch.stack([\n",
    "                V_1car[idx] / sigma_l2,\n",
    "                V_2car[idx] / sigma_l2\n",
    "        ], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_1car, P_2car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_1CAR = torch.tensor((choice['VOIT'] == 1).astype(int), dtype=torch.float64)\n",
    "        CHOICE_2CAR = torch.tensor((choice['VOIT'] >= 2).astype(int), dtype=torch.float64)\n",
    "\n",
    "        w = var('WEIGHT_hh')\n",
    "        w = w[idx]\n",
    "\n",
    "        epsilon=1e-30\n",
    "        LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.clamp(P_1car, min=epsilon))) +\n",
    "          torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.clamp(P_2car, min=epsilon))))\n",
    "        \n",
    "        if pytorch:\n",
    "                return -LL\n",
    "        \n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_1CAR[idx] * torch.log(torch.sum(CHOICE_1CAR[idx])/len(idx)))\n",
    "                        + torch.sum(w * CHOICE_2CAR[idx] * torch.log(torch.sum(CHOICE_2CAR[idx])/len(idx))))\n",
    "                return -null_LL\n",
    "        \n",
    "        if df_length:\n",
    "                return len(idx)\n",
    "        \n",
    "        if logsum:\n",
    "                LS_level2 = sigma_l2 * torch.log(\n",
    "                        torch.exp(V_1car/sigma_l2) + torch.exp(V_2car/sigma_l2)\n",
    "                )\n",
    "                return (LS_level2).detach().numpy()\n",
    "        \n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8410621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level2, parameters_level2 = Optimize(level2, \n",
    "        prepare_data_level2(df), \n",
    "        #  initial_values='Level2_CONSTRAINT',\n",
    "        max_iter=5000,\n",
    "        gtol=1,\n",
    "        display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level2,\n",
    "               parameters_level2,\n",
    "               excel=True,\n",
    "               data=prepare_data_level2(df),\n",
    "               file_name='Level2_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8aa5c8",
   "metadata": {},
   "source": [
    "# Level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15251f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_parameters = LoadParameters(\n",
    "                func=level2, \n",
    "                file_name='Level2_UNCONSTRAINT')\n",
    "\n",
    "df['LS_car'] = level2(loaded_parameters, prepare_data_level2(df), logsum=True)\n",
    "\n",
    "loaded_parameters = LoadParameters(\n",
    "                func=level1, \n",
    "                file_name='Level1_UNCONSTRAINT')\n",
    "\n",
    "df['V_BB'] = level1(loaded_parameters, prepare_data_level1(df), utility_nestB=True)\n",
    "\n",
    "def level3(params, \n",
    "                df, \n",
    "                pytorch=False, \n",
    "                grad=False, \n",
    "                null_loglik=False, \n",
    "                df_length=False,\n",
    "                logsum=False):\n",
    "        v = df[\"vars\"]\n",
    "\n",
    "        def var(name): return v[name]\n",
    "\n",
    "        if grad:\n",
    "                params = params.clone().requires_grad_(True)\n",
    "        else:\n",
    "                params = torch.tensor(params, dtype=torch.float64)\n",
    "\n",
    "        (sigma_l3,\n",
    "\n",
    "        ASC_car_l3) = params\n",
    "\n",
    "        XB_car = (torch.tensor(0))\n",
    "\n",
    "        V_NoCar = var('V_BB') \n",
    "        V_Car = ASC_car_l3 + XB_car + var('LS_car')\n",
    "\n",
    "        V_stack = torch.stack([\n",
    "                V_NoCar/sigma_l3, \n",
    "                V_Car/sigma_l3], dim=1)\n",
    "        max_V = V_stack.max()\n",
    "        exp_V = torch.exp(V_stack - max_V)\n",
    "        sum_exp = exp_V.sum(dim=1)\n",
    "\n",
    "        P_NoCar, P_Car = exp_V.T / sum_exp\n",
    "\n",
    "        choice = df['df']\n",
    "        CHOICE_NOCAR = torch.tensor((choice['VOIT'] == 0).astype(int), dtype=torch.float64)\n",
    "        CHOICE_CAR = torch.tensor((choice['VOIT'] >= 1).astype(int), dtype=torch.float64)\n",
    "\n",
    "        epsilon=1e-30\n",
    "        w = var('WEIGHT_hh')\n",
    "\n",
    "        LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.clamp(P_NoCar, min=epsilon))) +\n",
    "                torch.sum(w * CHOICE_CAR * torch.log(torch.clamp(P_Car, min=epsilon))))\n",
    "\n",
    "        if pytorch:\n",
    "                return -LL\n",
    "\n",
    "        if null_loglik:\n",
    "                null_LL = (torch.sum(w * CHOICE_NOCAR * torch.log(torch.sum(CHOICE_NOCAR)/len(CHOICE_NOCAR)))\n",
    "                        + torch.sum(w * CHOICE_CAR * torch.log(torch.sum(CHOICE_CAR)/len(CHOICE_CAR))))\n",
    "                return -null_LL\n",
    "\n",
    "        if df_length:\n",
    "                return len(df['df'])\n",
    "\n",
    "        if logsum:\n",
    "                LS_level3 = sigma_l3 * torch.log(\n",
    "                torch.exp(V_NoCar/sigma_l3) + torch.exp(V_Car/sigma_l3)\n",
    "                )\n",
    "                return (LS_level3).detach().numpy()\n",
    "\n",
    "        return (-LL).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff53e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_level3, parameters_level3 = Optimize(level3, \n",
    "         prepare_data_level3(df), \n",
    "        #  initial_values='Level3_CONSTRAINT',\n",
    "         display_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveParameters(level3,\n",
    "               parameters_level3,\n",
    "               excel=True,\n",
    "               data=prepare_data_level3(df),\n",
    "               file_name='Level3_CONSTRAINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0db95",
   "metadata": {},
   "source": [
    "# Simultaneous estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c60f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimultaneousNestLogitModel(params_all, df, null_loglik=False, pytorch=False, grad=False):\n",
    "\n",
    "    # here we need the lenght of the parameters of each level (except the last one)\n",
    "    p0 = len(LoadParameters(level0, 'Level0_UNCONSTRAINT'))\n",
    "    p1 = len(LoadParameters(level1, 'Level1_UNCONSTRAINT'))\n",
    "    p2 = len(LoadParameters(level2, 'Level2_UNCONSTRAINT'))\n",
    "\n",
    "    params0 = params_all[:p0]\n",
    "    params1 = params_all[p0:p0+p1]\n",
    "    params2 = params_all[p0+p1:p0+p1+p2]\n",
    "    params3 = params_all[p0+p1+p2:]\n",
    "\n",
    "    df0 = prepare_data_level0(df)\n",
    "    LS_m, LS_w = level0(params0, df0, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_m'] = LS_m\n",
    "    df['LS_w'] = LS_w\n",
    "\n",
    "    df1 = prepare_data_level1(df)\n",
    "    LS_1c, LS_2c = level1(params1, df1, logsum=True, all_sample=True)\n",
    "    V_BB = level1(params1, df1, utility_nestB=True, all_sample=True)\n",
    "\n",
    "    df['LS_1c'] = LS_1c\n",
    "    df['LS_2c'] = LS_2c\n",
    "\n",
    "    df2 = prepare_data_level2(df)\n",
    "    LS_car = level2(params2, df2, logsum=True, all_sample=True)\n",
    "\n",
    "    df['LS_car'] = LS_car\n",
    "    df['V_BB'] = V_BB\n",
    "\n",
    "    df3 = prepare_data_level3(df)\n",
    "\n",
    "    LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad)\n",
    "    LL3 = level3(params3, df3, pytorch=True, grad=grad)\n",
    "\n",
    "    total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    if null_loglik:\n",
    "        LL0 = level0(params0, df0, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL1 = level1(params1, df1, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL2 = level2(params2, df2, all_sample=True, pytorch=True, grad=grad, null_loglik=True)\n",
    "        LL3 = level3(params3, df3, pytorch=True, grad=grad, null_loglik=True)\n",
    "\n",
    "        total_LL = LL0 + LL1 + LL2 + LL3  \n",
    "\n",
    "    return total_LL if pytorch else total_LL.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcc579",
   "metadata": {},
   "source": [
    "### Mandatory :\n",
    "\n",
    "- You have to start the simultaneous estimation by using the parameters that you estimated independently on each level \n",
    "- This model is highly non-linear, which means that if you start by random values, it will almost never converge and will stay stuck in a local optima \n",
    "- Also, starting with those *independetly estimated parameters* will save you a lot of time in terms of computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12676793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from independent estimated parameters\n",
    "all_params = torch.cat([\n",
    "    LoadParameters(level0, 'Level0_UNCONSTRAINT'),\n",
    "    LoadParameters(level1, 'Level1_UNCONSTRAINT'),\n",
    "    LoadParameters(level2, 'Level2_UNCONSTRAINT'),\n",
    "    LoadParameters(level3, 'Level3_UNCONSTRAINT')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd3a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to start from your simultaneously estimated parameters \n",
    "# But they have to be estimated first, and then saved \n",
    "joint_parameters = JointLoadParameters(\n",
    "    file_name='Joint_UNCONSTRAINT',\n",
    "    level0=level0,\n",
    "    level1=level1,\n",
    "    level2=level2,\n",
    "    level3=level3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = JointOptimize(\n",
    "    func=SimultaneousNestLogitModel, \n",
    "    data=df, \n",
    "    initial_values=all_params, # start from independent estimated parameters\n",
    "    gtol=1,\n",
    "    max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will compute the summary table (can take some time because the model is big)\n",
    "# between 1 and 2min usually\n",
    "table = JointDisplayResults(\n",
    "               func=SimultaneousNestLogitModel,\n",
    "               params=parameters,\n",
    "               data=df,\n",
    "               level0=level0,\n",
    "               level1=level1,\n",
    "               level2=level2,\n",
    "               level3=level3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6a02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JointSaveParameters(params=parameters,\n",
    "                    level0=level0,\n",
    "                    level1=level1,\n",
    "                    level2=level2,\n",
    "                    level3=level3,\n",
    "                    table=table,\n",
    "                    excel=True,\n",
    "                    file_name='Joint_UNCONSTRAINT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
